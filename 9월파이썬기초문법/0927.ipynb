{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b7195d-9bf7-4c41-9d3d-33554f846992",
   "metadata": {},
   "source": [
    "# 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d8b9ea8-ad5a-4507-ba93-79da365fb0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\campus3s012\\desktop\\alphco\\venv\\lib\\site-packages (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6777dd1a-e50e-4228-a796-54a839fadd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98db826e-07b1-4221-aa48-131e63d4c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3769c71-9120-4335-97dc-269b154bee8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1 = [1, 2, 3]\n",
    "num2 = [4, 5, 6]\n",
    "# 569\n",
    "num1+num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af8f0ba8-045c-40c1-925e-004b7c3992d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 7, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1_arr = np.array(num1)\n",
    "num2_arr = np.array(num2)\n",
    "num1_arr+num2_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a727464-13e3-489a-a7da-a99c56737bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(num1_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f64ef3fe-52b9-4586-ba52-04df9de7b53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1_arr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43265462-1e53-401e-a13d-737dd91f2c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<memory at 0x0000025053317580>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1_arr.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b987d15-12e3-405e-87bc-5882932b5c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1_arr.dtype # 해당되는 배열의 데이터 타입을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f529d213-d2f7-40f6-a7b8-2455cd6356d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1_arr.shape #주로씀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaf20668-b45e-46f8-9bd9-1f1bd2a13ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1_arr.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c7001bf-23bd-42b9-8d69-7ebd02613d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1_arr.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e600fd8-c5bc-4c39-bc15-f382209a8eb6",
   "metadata": {},
   "source": [
    "# 우리 회사에서 주로 다루는 데이터는 0원 ~ 백만원 미만\n",
    "0~1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e05a0d2b-6c8c-4111-ac0d-f4b7ecfbbfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1_arr = np.array(num1, dtype = \"int8\")\n",
    "num1_arr.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c5205-1f97-43b8-9d7f-fac4788b6588",
   "metadata": {},
   "source": [
    "# 배열만드는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6e724e1-a34c-4012-8c50-1a115ff8961c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 기본적으로 다른 데이터 자료형으로 numpy 배열로 변환\n",
    "# 배열 생성\n",
    "print(np.ones(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a44630a5-c1df-4ae0-ae35-5bc336cd00a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.zeros(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0c2d678-f924-4761-bb25-eaffbd86ef06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr=np.ndarray(shape=(3, 3), dtype = float, order = 'f')\n",
    "# shape안에 콤마 만큼 차원이 늘어남 지금은 2차원\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b57456-bc57-4463-ad9c-eb179325d972",
   "metadata": {},
   "source": [
    "# 배열의 차원변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea67d7ce-7660-4064-8550-ba1ef8acf8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7]],\n",
       "\n",
       "       [[ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_arr = np.arange(16)\n",
    "temp_arr.reshape(2,2,4)  # 배열의 차원 변경 안에거를 곱해서 16만 나오면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587f7d7f-130e-4dfa-8da8-a938a7a3b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_arr = np.arange(16)\n",
    "temp_arr.reshape(2,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b5ad26c-c9f0-4fa2-bdc7-66a0f2ee3b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.333]\n",
      "[1.333333]\n"
     ]
    }
   ],
   "source": [
    "a16 = np.array([1.333333],dtype = np.float16)\n",
    "a32 = np.array([1.333333],dtype = np.float32)\n",
    "print(a16)\n",
    "print(a32)   \n",
    "# 두 결과는 전혀 다른값인 거고 무슨 비트로 받아서 처리할지 고려해야한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3cf112fd-3cd2-4965-b90a-bb1170cf610d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\campus3S012\\AppData\\Local\\Temp\\ipykernel_8024\\510923086.py:2: RuntimeWarning: divide by zero encountered in divide\n",
      "  arr/0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-inf,  inf, -inf])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([-1, 2, -3])\n",
    "arr/0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d54b837-7b0e-47f7-8537-2e045ce9bd08",
   "metadata": {},
   "source": [
    "결측치\n",
    "- missing values : 잃어버린 값\n",
    "- nan : not a number, --> 아직 정의되지 않은 숫자 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0c49d22-8fe1-49f4-9fd7-09ba600fbe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(np.nan, type(np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47bf1ff1-b8f0-4633-ad16-c32036967a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(np.inf, type(np.inf))   # inf는 무한대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f5973f7a-b314-4196-8505-288d470c47ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(-np.inf, type(-np.inf)) # 애네들이 정의한거니 그렇게 알기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f01cb0a8-6050-4fb3-9f1f-b332745bc867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan]\n",
      "[inf inf inf]\n"
     ]
    }
   ],
   "source": [
    "arr=np.array([-1,2,-3])\n",
    "print(arr + np.nan)\n",
    "print(arr + np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daa7a70-f849-4f68-afcf-8f3ca5c592a9",
   "metadata": {},
   "source": [
    "# 인덱싱 & 슬라이싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44d69633-4ee8-45e0-b64f-a3c10b83f715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(10)\n",
    "arr[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "181fd779-3154-4ae1-9579-b3214812633e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(10).reshape(2, 5)\n",
    "arr[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1d759e9d-728a-4210-86b3-124b6980a6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99],\n",
       "       [100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
       "        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
       "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
       "        139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,\n",
       "        152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
       "        165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177,\n",
       "        178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,\n",
       "        191, 192, 193, 194, 195, 196, 197, 198, 199]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(10000).reshape(100, 100)\n",
    "arr[0:2][0:5]   #[시작:최대 두블럭], [시작하는 블럭 순서:몇개까지 블럭 나오게할건지]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3325a17e-b565-446d-8d5f-ffdb9d40fb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(4)\n",
    "arr[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "71ea10b7-13fc-4aa1-832e-cd2ee71d6f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  8,  9],\n",
       "       [12, 13, 14],\n",
       "       [17, 18, 19]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arr[행:열\n",
    "arr = np.arange(20).reshape(4,5)\n",
    "arr[1:4,2:5] # arr[행:열]   arr[1: 끝까지 쓸거면 안써도됨]  arr[1:4,2:5] or arr[1:4]/arr[1:2:]      1:4,2:5 에서 2는 2열부터 5는 5행까지     [시작: 끝, 어디부터 시작할지:어디까지할지]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc544e9-8d7c-4710-a02c-0b7d7798dd07",
   "metadata": {},
   "source": [
    "# 브로드캐스팅 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d2383961-4b72-4490-bc90-3fc03977bf86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([1,2,3])\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c432aa9d-4cdd-4823-a94d-9df73d255169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 5., 6.])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3]) \n",
    "b=3.0  # 3.0의 값을 갖고 있는 1차 배열이 만들어져서 하나씩 더해졌다고 생각하면 됨\n",
    "a+b #각각 3.0을 더함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0fc889-bba3-4553-be78-fb462310b634",
   "metadata": {},
   "source": [
    "## 문제 1. \n",
    "문제: 모든 값이 0으로 2차원 배열 (5, 5) 만드세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5ff13bb2-b9f4-48bf-a0ff-b7dae522b402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a= np.zeros(25).reshape(5,5)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312dce4a-13b0-40e9-9c4e-5302dbc75dd0",
   "metadata": {},
   "source": [
    "## 문제 2. \n",
    "임의의 3x3 크기의 배열을 생성하고 배열의 shape(모양), dtype(데이터 타입), 그리고 배열의 차원 수(ndim)를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "919b781c-6cd6-491a-b32e-16d64d97aa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "(3, 3)\n",
      "int64\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a= np.arange(9).reshape(3,3)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.dtype)\n",
    "print(a.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafa4cf0-887f-458e-8492-6d67bc779629",
   "metadata": {},
   "source": [
    "## 문제 3. \n",
    "- 주어진 배열에서 아래와 같이 슬라이싱 하세요. \n",
    "```\n",
    "array([[ 5,  6],\n",
    "       [ 9, 10]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3bb341a6-ccca-45e3-9416-e844eb2daba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5,  6],\n",
       "       [ 9, 10]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(16).reshape(4,4)\n",
    "print (arr)\n",
    "arr[1:3,1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86b9c23-5ce1-43c7-9455-57b58650153a",
   "metadata": {},
   "source": [
    "# 조건 연산\n",
    "-원하는 결과값 : true/false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b2206d5e-7cb6-4044-9ab9-7e5b1317f523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr=np.array([10,20,30])\n",
    "arr>10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3ebd87c4-53bf-485f-bfa0-f1ae07c82b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 30])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr=np.array([10,20,30])\n",
    "cond = [False,  True,  True]\n",
    "\n",
    "arr[cond] #트루 값만 가져온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "51f837de-8bd0-4c7f-b793-ed5e9196deab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 50, 30])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr=np.array([18,20, 50, 30, 16])\n",
    "cond = arr > 18\n",
    "arr[cond] #트루값만 가져오니 필터처리한것다다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bd14353a-d6ab-4dc9-95b5-0a26bc930d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 50, 30])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr=np.array([18,20, 50, 30, 16])\n",
    "arr[arr > 18]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8eadfe59-92c4-4c00-bc1f-976f01d391fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 50, 30])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr=np.array([18,20, 50, 30, 16,65,70])\n",
    "cond0 = arr > 18\n",
    "cond1 = arr < 65\n",
    "\n",
    "arr[cond0 & cond1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4caa17e0-644d-4e9c-822a-319ad567f57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 20, 50, 30, 16, 65, 70])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[cond0 | cond1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "44e10fef-cd43-40a5-866f-f7eaf76e4eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 20, 50, 30, 16, 65, 70])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 권장사항 이유 판다스 : 다중조건 필터링할때는 아래방법으로만 가능\n",
    "# 반드시 ()가 필요\n",
    "arr[(cond0 | cond1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391ea259-326a-4384-8a11-0304257b08b9",
   "metadata": {},
   "source": [
    "## np.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6e1bc889-a20e-432c-99ae-cab535bfbcc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.arange(10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7bee58-ae3e-4665-9b9c-5f82d9735081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6003d85e-4a45-4c3d-a165-550403db81b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(a < 5, a, 10*a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784edc17-e87d-4366-ab1e-ac27ba764aa8",
   "metadata": {},
   "source": [
    "## 함수와 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "45e3ed5e-0ac1-475d-a9a6-a4d4e2cfa0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.int64(28)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr= np.arange(8).reshape(4,2)\n",
    "print(arr)\n",
    "arr.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e4c44ea6-9271-4189-9d02-064e276ceb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 16])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.sum(axis=0) #x축 방향으로 행단위의 데이터의 합을 구하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "35e2bd94-eb43-4b8a-b71f-55ff9e2de714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  5,  9, 13])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.sum(axis = 1) # y축 방향으로 열단위의 데이터의 합을 구하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bc166905-f045-4e36-80db-bcaba8f66492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#무작위 랜덤 함수 만들기\n",
    "np.random.seed(42) #나중에 머신러닝에서 씀 이거 쓰면 랜덤값이 안바뀜\n",
    "np.random.randint(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5701536d-6328-4df1-9750-21073345da60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43, 29, 37,  1],\n",
       "       [20, 32, 11, 21],\n",
       "       [43, 24, 26, 41]], dtype=int32)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(46, size =(3, 4)) # 46의미하는 것은 0~45번째까지중에 무작위로 가져오겠다는 뜻\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e6712b6c-5849-4d57-9932-991f2c6520b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.  10.  20.  30.  40.  50.  60.  70.  80.  90. 100.]\n"
     ]
    }
   ],
   "source": [
    "x= np.linspace(0,100,11) # linspace(시작값,종료값,균일값)는 균일하게 나누는거\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42519262-c34e-4fdd-af8c-25009a04dd64",
   "metadata": {},
   "source": [
    "# pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "157b6781-b953-43b2-a6b3-309a1110831a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.__version__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcdbc66b-38b4-4ae5-8f0b-84575393d65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1    20\n",
       "2    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [10, 20, 30]\n",
    "s = pd.Series(data)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d1e8ff-4fe2-48c9-9e4c-03419ccba557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd7507e-d41e-4261-a26a-1604c168e57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.arange(5)\n",
    "s = pd.Series(data)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac5c991d-a5fb-440d-a231-ab207a6fb645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  1\n",
       "2  2\n",
       "3  3\n",
       "4  4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.arange(5)\n",
    "s = pd.DataFrame(data)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "292eda43-f7aa-4f6f-9f09-fd1ae1501278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    tlrk\n",
       "1    rhrk\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\"tlrk\",\"rhrk\"]\n",
    "s=pd.Series(data)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82d9f70c-a880-4086-8050-2a65f63ce5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    80000\n",
       "1    90000\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\"80000\",\"90000\"]\n",
    "s=pd.Series(data)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cba0430-0652-41fb-8f11-7ff9b8cf11db",
   "metadata": {},
   "source": [
    "## 시리즈 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea4678a9-092d-48eb-9df4-2d084c95cd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=3, step=1) <class 'pandas.core.indexes.range.RangeIndex'>\n"
     ]
    }
   ],
   "source": [
    "data = [1000,2000,3000]\n",
    "s =pd.Series(data)\n",
    "print(s.index, type(s.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9836deb0-ea66-48a2-9a34-da7f2b0705b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(s.index) # 형변환 시킨것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10a437f9-308d-42e6-8639-622a3cb849df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.index.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90124941-04fc-45ba-8d0c-feb3aeeaec9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on RangeIndex in module pandas.core.indexes.range object:\n",
      "\n",
      "class RangeIndex(pandas.core.indexes.base.Index)\n",
      " |  RangeIndex(start=None, stop=None, step=None, dtype: 'Dtype | None' = None, copy: 'bool' = False, name: 'Hashable | None' = None) -> 'Self'\n",
      " |\n",
      " |  Immutable Index implementing a monotonic integer range.\n",
      " |\n",
      " |  RangeIndex is a memory-saving special case of an Index limited to representing\n",
      " |  monotonic ranges with a 64-bit dtype. Using RangeIndex may in some instances\n",
      " |  improve computing speed.\n",
      " |\n",
      " |  This is the default index type used\n",
      " |  by DataFrame and Series when no explicit index is provided by the user.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  start : int (default: 0), range, or other RangeIndex instance\n",
      " |      If int and \"stop\" is not given, interpreted as \"stop\" instead.\n",
      " |  stop : int (default: 0)\n",
      " |  step : int (default: 1)\n",
      " |  dtype : np.int64\n",
      " |      Unused, accepted for homogeneity with other index types.\n",
      " |  copy : bool, default False\n",
      " |      Unused, accepted for homogeneity with other index types.\n",
      " |  name : object, optional\n",
      " |      Name to be stored in the index.\n",
      " |\n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  start\n",
      " |  stop\n",
      " |  step\n",
      " |\n",
      " |  Methods\n",
      " |  -------\n",
      " |  from_range\n",
      " |\n",
      " |  See Also\n",
      " |  --------\n",
      " |  Index : The base pandas Index type.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> list(pd.RangeIndex(5))\n",
      " |  [0, 1, 2, 3, 4]\n",
      " |\n",
      " |  >>> list(pd.RangeIndex(-2, 4))\n",
      " |  [-2, -1, 0, 1, 2, 3]\n",
      " |\n",
      " |  >>> list(pd.RangeIndex(0, 10, 2))\n",
      " |  [0, 2, 4, 6, 8]\n",
      " |\n",
      " |  >>> list(pd.RangeIndex(2, -10, -3))\n",
      " |  [2, -1, -4, -7]\n",
      " |\n",
      " |  >>> list(pd.RangeIndex(0))\n",
      " |  []\n",
      " |\n",
      " |  >>> list(pd.RangeIndex(1, 0))\n",
      " |  []\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      RangeIndex\n",
      " |      pandas.core.indexes.base.Index\n",
      " |      pandas.core.base.IndexOpsMixin\n",
      " |      pandas.core.arraylike.OpsMixin\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.accessor.DirNamesMixin\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __contains__(self, key: 'Any') -> 'bool'\n",
      " |      Return a boolean indicating whether the provided key is in the index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : label\n",
      " |          The key to check if it is present in the index.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          Whether the key search is in the index.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If the key is not hashable.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.isin : Returns an ndarray of boolean dtype indicating whether the\n",
      " |          list-like key is in the index.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([1, 2, 3, 4])\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3, 4], dtype='int64')\n",
      " |\n",
      " |      >>> 2 in idx\n",
      " |      True\n",
      " |      >>> 6 in idx\n",
      " |      False\n",
      " |\n",
      " |  __floordiv__(self, other)\n",
      " |\n",
      " |  __getitem__(self, key)\n",
      " |      Conserve RangeIndex type for scalar and slice keys.\n",
      " |\n",
      " |  __iter__(self) -> 'Iterator[int]'\n",
      " |      Return an iterator of the values.\n",
      " |\n",
      " |      These are each a scalar type, which is a Python scalar\n",
      " |      (for str, int, float) or a pandas scalar\n",
      " |      (for Timestamp/Timedelta/Interval/Period)\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      iterator\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> for x in s:\n",
      " |      ...     print(x)\n",
      " |      1\n",
      " |      2\n",
      " |      3\n",
      " |\n",
      " |  __len__(self) -> 'int'\n",
      " |      return the length of the RangeIndex\n",
      " |\n",
      " |  __reduce__(self)\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  all(self, *args, **kwargs) -> 'bool'\n",
      " |      Return whether all elements are Truthy.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *args\n",
      " |          Required for compatibility with numpy.\n",
      " |      **kwargs\n",
      " |          Required for compatibility with numpy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool or array-like (if axis is specified)\n",
      " |          A single element array-like may be converted to bool.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.any : Return whether any element in an Index is True.\n",
      " |      Series.any : Return whether any element in a Series is True.\n",
      " |      Series.all : Return whether all elements in a Series are True.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Not a Number (NaN), positive infinity and negative infinity\n",
      " |      evaluate to True because these are not equal to zero.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      True, because nonzero integers are considered True.\n",
      " |\n",
      " |      >>> pd.Index([1, 2, 3]).all()\n",
      " |      True\n",
      " |\n",
      " |      False, because ``0`` is considered False.\n",
      " |\n",
      " |      >>> pd.Index([0, 1, 2]).all()\n",
      " |      False\n",
      " |\n",
      " |  any(self, *args, **kwargs) -> 'bool'\n",
      " |      Return whether any element is Truthy.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      *args\n",
      " |          Required for compatibility with numpy.\n",
      " |      **kwargs\n",
      " |          Required for compatibility with numpy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool or array-like (if axis is specified)\n",
      " |          A single element array-like may be converted to bool.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.all : Return whether all elements are True.\n",
      " |      Series.all : Return whether all elements are True.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Not a Number (NaN), positive infinity and negative infinity\n",
      " |      evaluate to True because these are not equal to zero.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = pd.Index([0, 1, 2])\n",
      " |      >>> index.any()\n",
      " |      True\n",
      " |\n",
      " |      >>> index = pd.Index([0, 0, 0])\n",
      " |      >>> index.any()\n",
      " |      False\n",
      " |\n",
      " |  argsort(self, *args, **kwargs) -> 'npt.NDArray[np.intp]'\n",
      " |      Returns the indices that would sort the index and its\n",
      " |      underlying data.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      np.ndarray[np.intp]\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.argsort\n",
      " |\n",
      " |  copy(self, name: 'Hashable | None' = None, deep: 'bool' = False) -> 'Self'\n",
      " |      Make a copy of this object.\n",
      " |\n",
      " |      Name is set on the new object.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : Label, optional\n",
      " |          Set name for new object.\n",
      " |      deep : bool, default False\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Index refer to new object which is a copy of this object.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      In most cases, there should be no functional difference from using\n",
      " |      ``deep``, but if ``deep`` is passed it will attempt to deepcopy.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index(['a', 'b', 'c'])\n",
      " |      >>> new_idx = idx.copy()\n",
      " |      >>> idx is new_idx\n",
      " |      False\n",
      " |\n",
      " |  delete(self, loc) -> 'Index'\n",
      " |      Make new Index with passed location(-s) deleted.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : int or list of int\n",
      " |          Location of item(-s) which will be deleted.\n",
      " |          Use a list of locations to delete more than one value at the same time.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Will be same type as self, except for RangeIndex.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.delete : Delete any rows and column from NumPy array (ndarray).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index(['a', 'b', 'c'])\n",
      " |      >>> idx.delete(1)\n",
      " |      Index(['a', 'c'], dtype='object')\n",
      " |\n",
      " |      >>> idx = pd.Index(['a', 'b', 'c'])\n",
      " |      >>> idx.delete([0, 2])\n",
      " |      Index(['b'], dtype='object')\n",
      " |\n",
      " |  equals(self, other: 'object') -> 'bool'\n",
      " |      Determines if two Index objects contain the same elements.\n",
      " |\n",
      " |  factorize(self, sort: 'bool' = False, use_na_sentinel: 'bool' = True) -> 'tuple[npt.NDArray[np.intp], RangeIndex]'\n",
      " |      Encode the object as an enumerated type or categorical variable.\n",
      " |\n",
      " |      This method is useful for obtaining a numeric representation of an\n",
      " |      array when all that matters is identifying distinct values. `factorize`\n",
      " |      is available as both a top-level function :func:`pandas.factorize`,\n",
      " |      and as a method :meth:`Series.factorize` and :meth:`Index.factorize`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sort : bool, default False\n",
      " |          Sort `uniques` and shuffle `codes` to maintain the\n",
      " |          relationship.\n",
      " |\n",
      " |      use_na_sentinel : bool, default True\n",
      " |          If True, the sentinel -1 will be used for NaN values. If False,\n",
      " |          NaN values will be encoded as non-negative integers and will not drop the\n",
      " |          NaN from the uniques of the values.\n",
      " |\n",
      " |          .. versionadded:: 1.5.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      codes : ndarray\n",
      " |          An integer ndarray that's an indexer into `uniques`.\n",
      " |          ``uniques.take(codes)`` will have the same values as `values`.\n",
      " |      uniques : ndarray, Index, or Categorical\n",
      " |          The unique valid values. When `values` is Categorical, `uniques`\n",
      " |          is a Categorical. When `values` is some other pandas object, an\n",
      " |          `Index` is returned. Otherwise, a 1-D ndarray is returned.\n",
      " |\n",
      " |          .. note::\n",
      " |\n",
      " |             Even if there's a missing value in `values`, `uniques` will\n",
      " |             *not* contain an entry for it.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      cut : Discretize continuous-valued array.\n",
      " |      unique : Find the unique value in an array.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Reference :ref:`the user guide <reshaping.factorize>` for more examples.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      These examples all show factorize as a top-level method like\n",
      " |      ``pd.factorize(values)``. The results are identical for methods like\n",
      " |      :meth:`Series.factorize`.\n",
      " |\n",
      " |      >>> codes, uniques = pd.factorize(np.array(['b', 'b', 'a', 'c', 'b'], dtype=\"O\"))\n",
      " |      >>> codes\n",
      " |      array([0, 0, 1, 2, 0])\n",
      " |      >>> uniques\n",
      " |      array(['b', 'a', 'c'], dtype=object)\n",
      " |\n",
      " |      With ``sort=True``, the `uniques` will be sorted, and `codes` will be\n",
      " |      shuffled so that the relationship is the maintained.\n",
      " |\n",
      " |      >>> codes, uniques = pd.factorize(np.array(['b', 'b', 'a', 'c', 'b'], dtype=\"O\"),\n",
      " |      ...                               sort=True)\n",
      " |      >>> codes\n",
      " |      array([1, 1, 0, 2, 1])\n",
      " |      >>> uniques\n",
      " |      array(['a', 'b', 'c'], dtype=object)\n",
      " |\n",
      " |      When ``use_na_sentinel=True`` (the default), missing values are indicated in\n",
      " |      the `codes` with the sentinel value ``-1`` and missing values are not\n",
      " |      included in `uniques`.\n",
      " |\n",
      " |      >>> codes, uniques = pd.factorize(np.array(['b', None, 'a', 'c', 'b'], dtype=\"O\"))\n",
      " |      >>> codes\n",
      " |      array([ 0, -1,  1,  2,  0])\n",
      " |      >>> uniques\n",
      " |      array(['b', 'a', 'c'], dtype=object)\n",
      " |\n",
      " |      Thus far, we've only factorized lists (which are internally coerced to\n",
      " |      NumPy arrays). When factorizing pandas objects, the type of `uniques`\n",
      " |      will differ. For Categoricals, a `Categorical` is returned.\n",
      " |\n",
      " |      >>> cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c'])\n",
      " |      >>> codes, uniques = pd.factorize(cat)\n",
      " |      >>> codes\n",
      " |      array([0, 0, 1])\n",
      " |      >>> uniques\n",
      " |      ['a', 'c']\n",
      " |      Categories (3, object): ['a', 'b', 'c']\n",
      " |\n",
      " |      Notice that ``'b'`` is in ``uniques.categories``, despite not being\n",
      " |      present in ``cat.values``.\n",
      " |\n",
      " |      For all other pandas objects, an Index of the appropriate type is\n",
      " |      returned.\n",
      " |\n",
      " |      >>> cat = pd.Series(['a', 'a', 'c'])\n",
      " |      >>> codes, uniques = pd.factorize(cat)\n",
      " |      >>> codes\n",
      " |      array([0, 0, 1])\n",
      " |      >>> uniques\n",
      " |      Index(['a', 'c'], dtype='object')\n",
      " |\n",
      " |      If NaN is in the values, and we want to include NaN in the uniques of the\n",
      " |      values, it can be achieved by setting ``use_na_sentinel=False``.\n",
      " |\n",
      " |      >>> values = np.array([1, 2, 1, np.nan])\n",
      " |      >>> codes, uniques = pd.factorize(values)  # default: use_na_sentinel=True\n",
      " |      >>> codes\n",
      " |      array([ 0,  1,  0, -1])\n",
      " |      >>> uniques\n",
      " |      array([1., 2.])\n",
      " |\n",
      " |      >>> codes, uniques = pd.factorize(values, use_na_sentinel=False)\n",
      " |      >>> codes\n",
      " |      array([0, 1, 0, 2])\n",
      " |      >>> uniques\n",
      " |      array([ 1.,  2., nan])\n",
      " |\n",
      " |  get_loc(self, key) -> 'int'\n",
      " |      Get integer location, slice or boolean mask for requested label.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : label\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      int if unique index, slice if monotonic index, else mask\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> unique_index = pd.Index(list('abc'))\n",
      " |      >>> unique_index.get_loc('b')\n",
      " |      1\n",
      " |\n",
      " |      >>> monotonic_index = pd.Index(list('abbc'))\n",
      " |      >>> monotonic_index.get_loc('b')\n",
      " |      slice(1, 3, None)\n",
      " |\n",
      " |      >>> non_monotonic_index = pd.Index(list('abcb'))\n",
      " |      >>> non_monotonic_index.get_loc('b')\n",
      " |      array([False,  True, False,  True])\n",
      " |\n",
      " |  insert(self, loc: 'int', item) -> 'Index'\n",
      " |      Make new Index inserting new item at location.\n",
      " |\n",
      " |      Follows Python numpy.insert semantics for negative values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : int\n",
      " |      item : object\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index(['a', 'b', 'c'])\n",
      " |      >>> idx.insert(1, 'x')\n",
      " |      Index(['a', 'x', 'b', 'c'], dtype='object')\n",
      " |\n",
      " |  max(self, axis=None, skipna: 'bool' = True, *args, **kwargs) -> 'int'\n",
      " |      The maximum value of the RangeIndex\n",
      " |\n",
      " |  memory_usage(self, deep: 'bool' = False) -> 'int'\n",
      " |      Memory usage of my values\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool\n",
      " |          Introspect the data deeply, interrogate\n",
      " |          `object` dtypes for system-level memory consumption\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bytes used\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Memory usage does not include memory consumed by elements that\n",
      " |      are not components of the array if deep=False\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes\n",
      " |\n",
      " |  min(self, axis=None, skipna: 'bool' = True, *args, **kwargs) -> 'int'\n",
      " |      The minimum value of the RangeIndex\n",
      " |\n",
      " |  sort_values(self, *, return_indexer: 'bool' = False, ascending: 'bool' = True, na_position: 'NaPosition' = 'last', key: 'Callable | None' = None) -> 'Self | tuple[Self, np.ndarray | RangeIndex]'\n",
      " |      Return a sorted copy of the index.\n",
      " |\n",
      " |      Return a sorted copy of the index, and optionally return the indices\n",
      " |      that sorted the index itself.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      return_indexer : bool, default False\n",
      " |          Should the indices that would sort the index be returned.\n",
      " |      ascending : bool, default True\n",
      " |          Should the index values be sorted in an ascending order.\n",
      " |      na_position : {'first' or 'last'}, default 'last'\n",
      " |          Argument 'first' puts NaNs at the beginning, 'last' puts NaNs at\n",
      " |          the end.\n",
      " |      key : callable, optional\n",
      " |          If not None, apply the key function to the index values\n",
      " |          before sorting. This is similar to the `key` argument in the\n",
      " |          builtin :meth:`sorted` function, with the notable difference that\n",
      " |          this `key` function should be *vectorized*. It should expect an\n",
      " |          ``Index`` and return an ``Index`` of the same shape.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted_index : pandas.Index\n",
      " |          Sorted copy of the index.\n",
      " |      indexer : numpy.ndarray, optional\n",
      " |          The indices that the index itself was sorted by.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.sort_values : Sort values of a Series.\n",
      " |      DataFrame.sort_values : Sort values in a DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([10, 100, 1, 1000])\n",
      " |      >>> idx\n",
      " |      Index([10, 100, 1, 1000], dtype='int64')\n",
      " |\n",
      " |      Sort values in ascending order (default behavior).\n",
      " |\n",
      " |      >>> idx.sort_values()\n",
      " |      Index([1, 10, 100, 1000], dtype='int64')\n",
      " |\n",
      " |      Sort values in descending order, and also get the indices `idx` was\n",
      " |      sorted by.\n",
      " |\n",
      " |      >>> idx.sort_values(ascending=False, return_indexer=True)\n",
      " |      (Index([1000, 100, 10, 1], dtype='int64'), array([3, 1, 0, 2]))\n",
      " |\n",
      " |  symmetric_difference(self, other, result_name: 'Hashable | None' = None, sort=None)\n",
      " |      Compute the symmetric difference of two Index objects.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Index or array-like\n",
      " |      result_name : str\n",
      " |      sort : bool or None, default None\n",
      " |          Whether to sort the resulting index. By default, the\n",
      " |          values are attempted to be sorted, but any TypeError from\n",
      " |          incomparable elements is caught by pandas.\n",
      " |\n",
      " |          * None : Attempt to sort the result, but catch any TypeErrors\n",
      " |            from comparing incomparable elements.\n",
      " |          * False : Do not sort the result.\n",
      " |          * True : Sort the result (which may raise TypeError).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      ``symmetric_difference`` contains elements that appear in either\n",
      " |      ``idx1`` or ``idx2`` but not both. Equivalent to the Index created by\n",
      " |      ``idx1.difference(idx2) | idx2.difference(idx1)`` with duplicates\n",
      " |      dropped.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx1 = pd.Index([1, 2, 3, 4])\n",
      " |      >>> idx2 = pd.Index([2, 3, 4, 5])\n",
      " |      >>> idx1.symmetric_difference(idx2)\n",
      " |      Index([1, 5], dtype='int64')\n",
      " |\n",
      " |  take(self, indices, axis: 'Axis' = 0, allow_fill: 'bool' = True, fill_value=None, **kwargs) -> 'Index'\n",
      " |      Return a new Index of the values selected by the indices.\n",
      " |\n",
      " |      For internal compatibility with numpy arrays.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : array-like\n",
      " |          Indices to be taken.\n",
      " |      axis : int, optional\n",
      " |          The axis over which to select values, always 0.\n",
      " |      allow_fill : bool, default True\n",
      " |      fill_value : scalar, default None\n",
      " |          If allow_fill=True and fill_value is not None, indices specified by\n",
      " |          -1 are regarded as NA. If Index doesn't hold NA, raise ValueError.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          An index formed of elements at the given indices. Will be the same\n",
      " |          type as self, except for RangeIndex.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.take: Return an array formed from the\n",
      " |          elements of a at the given indices.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index(['a', 'b', 'c'])\n",
      " |      >>> idx.take([2, 2, 1, 2])\n",
      " |      Index(['c', 'c', 'b', 'c'], dtype='object')\n",
      " |\n",
      " |  tolist(self) -> 'list[int]'\n",
      " |      Return a list of the values.\n",
      " |\n",
      " |      These are each a scalar type, which is a Python scalar\n",
      " |      (for str, int, float) or a pandas scalar\n",
      " |      (for Timestamp/Timedelta/Interval/Period)\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      list\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.tolist : Return the array as an a.ndim-levels deep\n",
      " |          nested list of Python scalars.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.to_list()\n",
      " |      [1, 2, 3]\n",
      " |\n",
      " |      For Index:\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |\n",
      " |      >>> idx.to_list()\n",
      " |      [1, 2, 3]\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |\n",
      " |  from_range(data: 'range', name=None, dtype: 'Dtype | None' = None) -> 'Self'\n",
      " |      Create :class:`pandas.RangeIndex` from a ``range`` object.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      RangeIndex\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> pd.RangeIndex.from_range(range(5))\n",
      " |      RangeIndex(start=0, stop=5, step=1)\n",
      " |\n",
      " |      >>> pd.RangeIndex.from_range(range(2, -10, -3))\n",
      " |      RangeIndex(start=2, stop=-10, step=-3)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |\n",
      " |  __new__(cls, start=None, stop=None, step=None, dtype: 'Dtype | None' = None, copy: 'bool' = False, name: 'Hashable | None' = None) -> 'Self'\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  dtype\n",
      " |      Return the dtype object of the underlying data.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |      >>> idx.dtype\n",
      " |      dtype('int64')\n",
      " |\n",
      " |  inferred_type\n",
      " |      Return a string of the type inferred from the values.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |      >>> idx.inferred_type\n",
      " |      'integer'\n",
      " |\n",
      " |  is_unique\n",
      " |      return if the index has unique values\n",
      " |\n",
      " |  size\n",
      " |      Return the number of elements in the underlying data.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |\n",
      " |      >>> s = pd.Series(['Ant', 'Bear', 'Cow'])\n",
      " |      >>> s\n",
      " |      0     Ant\n",
      " |      1    Bear\n",
      " |      2     Cow\n",
      " |      dtype: object\n",
      " |      >>> s.size\n",
      " |      3\n",
      " |\n",
      " |      For Index:\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |      >>> idx.size\n",
      " |      3\n",
      " |\n",
      " |  start\n",
      " |      The value of the `start` parameter (``0`` if this was not supplied).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.RangeIndex(5)\n",
      " |      >>> idx.start\n",
      " |      0\n",
      " |\n",
      " |      >>> idx = pd.RangeIndex(2, -10, -3)\n",
      " |      >>> idx.start\n",
      " |      2\n",
      " |\n",
      " |  step\n",
      " |      The value of the `step` parameter (``1`` if this was not supplied).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.RangeIndex(5)\n",
      " |      >>> idx.step\n",
      " |      1\n",
      " |\n",
      " |      >>> idx = pd.RangeIndex(2, -10, -3)\n",
      " |      >>> idx.step\n",
      " |      -3\n",
      " |\n",
      " |      Even if :class:`pandas.RangeIndex` is empty, ``step`` is still ``1`` if\n",
      " |      not supplied.\n",
      " |\n",
      " |      >>> idx = pd.RangeIndex(1, 0)\n",
      " |      >>> idx.step\n",
      " |      1\n",
      " |\n",
      " |  stop\n",
      " |      The value of the `stop` parameter.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.RangeIndex(5)\n",
      " |      >>> idx.stop\n",
      " |      5\n",
      " |\n",
      " |      >>> idx = pd.RangeIndex(2, -10, -3)\n",
      " |      >>> idx.stop\n",
      " |      -10\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  is_monotonic_decreasing\n",
      " |\n",
      " |  is_monotonic_increasing\n",
      " |\n",
      " |  nbytes\n",
      " |      Return the number of bytes in the underlying data.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {'_range': 'range', '_values': 'np.ndarray'}\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.indexes.base.Index:\n",
      " |\n",
      " |  __abs__(self) -> 'Index'\n",
      " |\n",
      " |  __array__(self, dtype=None, copy=None) -> 'np.ndarray'\n",
      " |      The array interface, return my values.\n",
      " |\n",
      " |  __array_ufunc__(self, ufunc: 'np.ufunc', method: 'str_t', *inputs, **kwargs)\n",
      " |\n",
      " |  __array_wrap__(self, result, context=None, return_scalar=False)\n",
      " |      Gets called after a ufunc and other functions e.g. np.split.\n",
      " |\n",
      " |  __bool__ = __nonzero__(self) -> 'NoReturn'\n",
      " |\n",
      " |  __copy__(self, **kwargs) -> 'Self'\n",
      " |\n",
      " |  __deepcopy__(self, memo=None) -> 'Self'\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      memo, default None\n",
      " |          Standard signature. Unused\n",
      " |\n",
      " |  __iadd__(self, other)\n",
      " |\n",
      " |  __invert__(self) -> 'Index'\n",
      " |\n",
      " |  __neg__(self) -> 'Index'\n",
      " |\n",
      " |  __nonzero__(self) -> 'NoReturn'\n",
      " |\n",
      " |  __pos__(self) -> 'Index'\n",
      " |\n",
      " |  __repr__(self) -> 'str_t'\n",
      " |      Return a string representation for this object.\n",
      " |\n",
      " |  __setitem__(self, key, value) -> 'None'\n",
      " |\n",
      " |  append(self, other: 'Index | Sequence[Index]') -> 'Index'\n",
      " |      Append a collection of Index options together.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Index or list/tuple of indices\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx.append(pd.Index([4]))\n",
      " |      Index([1, 2, 3, 4], dtype='int64')\n",
      " |\n",
      " |  argmax(self, axis=None, skipna: 'bool' = True, *args, **kwargs) -> 'int'\n",
      " |      Return int position of the largest value in the Series.\n",
      " |\n",
      " |      If the maximum is achieved in multiple locations,\n",
      " |      the first row position is returned.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {None}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when showing the result.\n",
      " |      *args, **kwargs\n",
      " |          Additional arguments and keywords for compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          Row position of the maximum value.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.argmax : Return position of the maximum value.\n",
      " |      Series.argmin : Return position of the minimum value.\n",
      " |      numpy.ndarray.argmax : Equivalent method for numpy arrays.\n",
      " |      Series.idxmax : Return index label of the maximum values.\n",
      " |      Series.idxmin : Return index label of the minimum values.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing cereal calories\n",
      " |\n",
      " |      >>> s = pd.Series({'Corn Flakes': 100.0, 'Almond Delight': 110.0,\n",
      " |      ...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0})\n",
      " |      >>> s\n",
      " |      Corn Flakes              100.0\n",
      " |      Almond Delight           110.0\n",
      " |      Cinnamon Toast Crunch    120.0\n",
      " |      Cocoa Puff               110.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s.argmax()\n",
      " |      2\n",
      " |      >>> s.argmin()\n",
      " |      0\n",
      " |\n",
      " |      The maximum cereal calories is the third element and\n",
      " |      the minimum cereal calories is the first element,\n",
      " |      since series is zero-indexed.\n",
      " |\n",
      " |  argmin(self, axis=None, skipna: 'bool' = True, *args, **kwargs) -> 'int'\n",
      " |      Return int position of the smallest value in the Series.\n",
      " |\n",
      " |      If the minimum is achieved in multiple locations,\n",
      " |      the first row position is returned.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {None}\n",
      " |          Unused. Parameter needed for compatibility with DataFrame.\n",
      " |      skipna : bool, default True\n",
      " |          Exclude NA/null values when showing the result.\n",
      " |      *args, **kwargs\n",
      " |          Additional arguments and keywords for compatibility with NumPy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          Row position of the minimum value.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.argmin : Return position of the minimum value.\n",
      " |      Series.argmax : Return position of the maximum value.\n",
      " |      numpy.ndarray.argmin : Equivalent method for numpy arrays.\n",
      " |      Series.idxmax : Return index label of the maximum values.\n",
      " |      Series.idxmin : Return index label of the minimum values.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Consider dataset containing cereal calories\n",
      " |\n",
      " |      >>> s = pd.Series({'Corn Flakes': 100.0, 'Almond Delight': 110.0,\n",
      " |      ...                'Cinnamon Toast Crunch': 120.0, 'Cocoa Puff': 110.0})\n",
      " |      >>> s\n",
      " |      Corn Flakes              100.0\n",
      " |      Almond Delight           110.0\n",
      " |      Cinnamon Toast Crunch    120.0\n",
      " |      Cocoa Puff               110.0\n",
      " |      dtype: float64\n",
      " |\n",
      " |      >>> s.argmax()\n",
      " |      2\n",
      " |      >>> s.argmin()\n",
      " |      0\n",
      " |\n",
      " |      The maximum cereal calories is the third element and\n",
      " |      the minimum cereal calories is the first element,\n",
      " |      since series is zero-indexed.\n",
      " |\n",
      " |  asof(self, label)\n",
      " |      Return the label from the index, or, if not present, the previous one.\n",
      " |\n",
      " |      Assuming that the index is sorted, return the passed index label if it\n",
      " |      is in the index, or return the previous index label if the passed one\n",
      " |      is not in the index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      label : object\n",
      " |          The label up to which the method returns the latest index label.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      object\n",
      " |          The passed label if it is in the index. The previous label if the\n",
      " |          passed label is not in the sorted index or `NaN` if there is no\n",
      " |          such label.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.asof : Return the latest value in a Series up to the\n",
      " |          passed index.\n",
      " |      merge_asof : Perform an asof merge (similar to left join but it\n",
      " |          matches on nearest key rather than equal key).\n",
      " |      Index.get_loc : An `asof` is a thin wrapper around `get_loc`\n",
      " |          with method='pad'.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      `Index.asof` returns the latest index label up to the passed label.\n",
      " |\n",
      " |      >>> idx = pd.Index(['2013-12-31', '2014-01-02', '2014-01-03'])\n",
      " |      >>> idx.asof('2014-01-01')\n",
      " |      '2013-12-31'\n",
      " |\n",
      " |      If the label is in the index, the method returns the passed label.\n",
      " |\n",
      " |      >>> idx.asof('2014-01-02')\n",
      " |      '2014-01-02'\n",
      " |\n",
      " |      If all of the labels in the index are later than the passed label,\n",
      " |      NaN is returned.\n",
      " |\n",
      " |      >>> idx.asof('1999-01-02')\n",
      " |      nan\n",
      " |\n",
      " |      If the index is not sorted, an error is raised.\n",
      " |\n",
      " |      >>> idx_not_sorted = pd.Index(['2013-12-31', '2015-01-02',\n",
      " |      ...                            '2014-01-03'])\n",
      " |      >>> idx_not_sorted.asof('2013-12-31')\n",
      " |      Traceback (most recent call last):\n",
      " |      ValueError: index must be monotonic increasing or decreasing\n",
      " |\n",
      " |  asof_locs(self, where: 'Index', mask: 'npt.NDArray[np.bool_]') -> 'npt.NDArray[np.intp]'\n",
      " |      Return the locations (indices) of labels in the index.\n",
      " |\n",
      " |      As in the :meth:`pandas.Index.asof`, if the label (a particular entry in\n",
      " |      ``where``) is not in the index, the latest index label up to the\n",
      " |      passed label is chosen and its index returned.\n",
      " |\n",
      " |      If all of the labels in the index are later than a label in ``where``,\n",
      " |      -1 is returned.\n",
      " |\n",
      " |      ``mask`` is used to ignore ``NA`` values in the index during calculation.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      where : Index\n",
      " |          An Index consisting of an array of timestamps.\n",
      " |      mask : np.ndarray[bool]\n",
      " |          Array of booleans denoting where values in the original\n",
      " |          data are not ``NA``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      np.ndarray[np.intp]\n",
      " |          An array of locations (indices) of the labels from the index\n",
      " |          which correspond to the return values of :meth:`pandas.Index.asof`\n",
      " |          for every element in ``where``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.asof : Return the label from the index, or, if not present, the\n",
      " |          previous one.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.date_range('2023-06-01', periods=3, freq='D')\n",
      " |      >>> where = pd.DatetimeIndex(['2023-05-30 00:12:00', '2023-06-01 00:00:00',\n",
      " |      ...                           '2023-06-02 23:59:59'])\n",
      " |      >>> mask = np.ones(3, dtype=bool)\n",
      " |      >>> idx.asof_locs(where, mask)\n",
      " |      array([-1,  0,  1])\n",
      " |\n",
      " |      We can use ``mask`` to ignore certain values in the index during calculation.\n",
      " |\n",
      " |      >>> mask[1] = False\n",
      " |      >>> idx.asof_locs(where, mask)\n",
      " |      array([-1,  0,  0])\n",
      " |\n",
      " |  astype(self, dtype, copy: 'bool' = True)\n",
      " |      Create an Index with values cast to dtypes.\n",
      " |\n",
      " |      The class of a new Index is determined by dtype. When conversion is\n",
      " |      impossible, a TypeError exception is raised.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : numpy dtype or pandas type\n",
      " |          Note that any signed integer `dtype` is treated as ``'int64'``,\n",
      " |          and any unsigned integer `dtype` is treated as ``'uint64'``,\n",
      " |          regardless of the size.\n",
      " |      copy : bool, default True\n",
      " |          By default, astype always returns a newly allocated object.\n",
      " |          If copy is set to False and internal requirements on dtype are\n",
      " |          satisfied, the original data is used to create a new Index\n",
      " |          or the original Index is returned.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Index with values cast to specified dtype.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |      >>> idx.astype('float')\n",
      " |      Index([1.0, 2.0, 3.0], dtype='float64')\n",
      " |\n",
      " |  diff(self, periods: 'int' = 1) -> 'Index'\n",
      " |      Computes the difference between consecutive values in the Index object.\n",
      " |\n",
      " |      If periods is greater than 1, computes the difference between values that\n",
      " |      are `periods` number of positions apart.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, optional\n",
      " |          The number of positions between the current and previous\n",
      " |          value to compute the difference with. Default is 1.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          A new Index object with the computed differences.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> idx = pd.Index([10, 20, 30, 40, 50])\n",
      " |      >>> idx.diff()\n",
      " |      Index([nan, 10.0, 10.0, 10.0, 10.0], dtype='float64')\n",
      " |\n",
      " |  difference(self, other, sort=None)\n",
      " |      Return a new Index with elements of index not in `other`.\n",
      " |\n",
      " |      This is the set difference of two Index objects.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Index or array-like\n",
      " |      sort : bool or None, default None\n",
      " |          Whether to sort the resulting index. By default, the\n",
      " |          values are attempted to be sorted, but any TypeError from\n",
      " |          incomparable elements is caught by pandas.\n",
      " |\n",
      " |          * None : Attempt to sort the result, but catch any TypeErrors\n",
      " |            from comparing incomparable elements.\n",
      " |          * False : Do not sort the result.\n",
      " |          * True : Sort the result (which may raise TypeError).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx1 = pd.Index([2, 1, 3, 4])\n",
      " |      >>> idx2 = pd.Index([3, 4, 5, 6])\n",
      " |      >>> idx1.difference(idx2)\n",
      " |      Index([1, 2], dtype='int64')\n",
      " |      >>> idx1.difference(idx2, sort=False)\n",
      " |      Index([2, 1], dtype='int64')\n",
      " |\n",
      " |  drop(self, labels: 'Index | np.ndarray | Iterable[Hashable]', errors: 'IgnoreRaise' = 'raise') -> 'Index'\n",
      " |      Make new Index with passed list of labels deleted.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : array-like or scalar\n",
      " |      errors : {'ignore', 'raise'}, default 'raise'\n",
      " |          If 'ignore', suppress error and existing labels are dropped.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Will be same type as self, except for RangeIndex.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError\n",
      " |          If not all of the labels are found in the selected axis\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index(['a', 'b', 'c'])\n",
      " |      >>> idx.drop(['a'])\n",
      " |      Index(['b', 'c'], dtype='object')\n",
      " |\n",
      " |  drop_duplicates(self, *, keep: 'DropKeep' = 'first') -> 'Self'\n",
      " |      Return Index with duplicate values removed.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', ``False``}, default 'first'\n",
      " |          - 'first' : Drop duplicates except for the first occurrence.\n",
      " |          - 'last' : Drop duplicates except for the last occurrence.\n",
      " |          - ``False`` : Drop all duplicates.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.drop_duplicates : Equivalent method on Series.\n",
      " |      DataFrame.drop_duplicates : Equivalent method on DataFrame.\n",
      " |      Index.duplicated : Related method on Index, indicating duplicate\n",
      " |          Index values.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Generate an pandas.Index with duplicate values.\n",
      " |\n",
      " |      >>> idx = pd.Index(['lama', 'cow', 'lama', 'beetle', 'lama', 'hippo'])\n",
      " |\n",
      " |      The `keep` parameter controls  which duplicate values are removed.\n",
      " |      The value 'first' keeps the first occurrence for each\n",
      " |      set of duplicated entries. The default value of keep is 'first'.\n",
      " |\n",
      " |      >>> idx.drop_duplicates(keep='first')\n",
      " |      Index(['lama', 'cow', 'beetle', 'hippo'], dtype='object')\n",
      " |\n",
      " |      The value 'last' keeps the last occurrence for each set of duplicated\n",
      " |      entries.\n",
      " |\n",
      " |      >>> idx.drop_duplicates(keep='last')\n",
      " |      Index(['cow', 'beetle', 'lama', 'hippo'], dtype='object')\n",
      " |\n",
      " |      The value ``False`` discards all sets of duplicated entries.\n",
      " |\n",
      " |      >>> idx.drop_duplicates(keep=False)\n",
      " |      Index(['cow', 'beetle', 'hippo'], dtype='object')\n",
      " |\n",
      " |  droplevel(self, level: 'IndexLabel' = 0)\n",
      " |      Return index with requested level(s) removed.\n",
      " |\n",
      " |      If resulting index has only 1 level left, the result will be\n",
      " |      of Index type, not MultiIndex. The original index is not modified inplace.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, or list-like, default 0\n",
      " |          If a string is given, must be the name of a level\n",
      " |          If list-like, elements must be names or indexes of levels.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index or MultiIndex\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> mi = pd.MultiIndex.from_arrays(\n",
      " |      ... [[1, 2], [3, 4], [5, 6]], names=['x', 'y', 'z'])\n",
      " |      >>> mi\n",
      " |      MultiIndex([(1, 3, 5),\n",
      " |                  (2, 4, 6)],\n",
      " |                 names=['x', 'y', 'z'])\n",
      " |\n",
      " |      >>> mi.droplevel()\n",
      " |      MultiIndex([(3, 5),\n",
      " |                  (4, 6)],\n",
      " |                 names=['y', 'z'])\n",
      " |\n",
      " |      >>> mi.droplevel(2)\n",
      " |      MultiIndex([(1, 3),\n",
      " |                  (2, 4)],\n",
      " |                 names=['x', 'y'])\n",
      " |\n",
      " |      >>> mi.droplevel('z')\n",
      " |      MultiIndex([(1, 3),\n",
      " |                  (2, 4)],\n",
      " |                 names=['x', 'y'])\n",
      " |\n",
      " |      >>> mi.droplevel(['x', 'y'])\n",
      " |      Index([5, 6], dtype='int64', name='z')\n",
      " |\n",
      " |  dropna(self, how: 'AnyAll' = 'any') -> 'Self'\n",
      " |      Return Index without NA/NaN values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      how : {'any', 'all'}, default 'any'\n",
      " |          If the Index is a MultiIndex, drop the value when any or all levels\n",
      " |          are NaN.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([1, np.nan, 3])\n",
      " |      >>> idx.dropna()\n",
      " |      Index([1.0, 3.0], dtype='float64')\n",
      " |\n",
      " |  duplicated(self, keep: 'DropKeep' = 'first') -> 'npt.NDArray[np.bool_]'\n",
      " |      Indicate duplicate index values.\n",
      " |\n",
      " |      Duplicated values are indicated as ``True`` values in the resulting\n",
      " |      array. Either all duplicates, all except the first, or all except the\n",
      " |      last occurrence of duplicates can be indicated.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keep : {'first', 'last', False}, default 'first'\n",
      " |          The value or values in a set of duplicates to mark as missing.\n",
      " |\n",
      " |          - 'first' : Mark duplicates as ``True`` except for the first\n",
      " |            occurrence.\n",
      " |          - 'last' : Mark duplicates as ``True`` except for the last\n",
      " |            occurrence.\n",
      " |          - ``False`` : Mark all duplicates as ``True``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      np.ndarray[bool]\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.duplicated : Equivalent method on pandas.Series.\n",
      " |      DataFrame.duplicated : Equivalent method on pandas.DataFrame.\n",
      " |      Index.drop_duplicates : Remove duplicate values from Index.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      By default, for each set of duplicated values, the first occurrence is\n",
      " |      set to False and all others to True:\n",
      " |\n",
      " |      >>> idx = pd.Index(['lama', 'cow', 'lama', 'beetle', 'lama'])\n",
      " |      >>> idx.duplicated()\n",
      " |      array([False, False,  True, False,  True])\n",
      " |\n",
      " |      which is equivalent to\n",
      " |\n",
      " |      >>> idx.duplicated(keep='first')\n",
      " |      array([False, False,  True, False,  True])\n",
      " |\n",
      " |      By using 'last', the last occurrence of each set of duplicated values\n",
      " |      is set on False and all others on True:\n",
      " |\n",
      " |      >>> idx.duplicated(keep='last')\n",
      " |      array([ True, False,  True, False, False])\n",
      " |\n",
      " |      By setting keep on ``False``, all duplicates are True:\n",
      " |\n",
      " |      >>> idx.duplicated(keep=False)\n",
      " |      array([ True, False,  True, False,  True])\n",
      " |\n",
      " |  fillna(self, value=None, downcast=<no_default>)\n",
      " |      Fill NA/NaN values with the specified value.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : scalar\n",
      " |          Scalar value to use to fill holes (e.g. 0).\n",
      " |          This value cannot be a list-likes.\n",
      " |      downcast : dict, default is None\n",
      " |          A dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible).\n",
      " |\n",
      " |          .. deprecated:: 2.1.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.fillna : Fill NaN values of a DataFrame.\n",
      " |      Series.fillna : Fill NaN Values of a Series.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([np.nan, np.nan, 3])\n",
      " |      >>> idx.fillna(0)\n",
      " |      Index([0.0, 0.0, 3.0], dtype='float64')\n",
      " |\n",
      " |  format(self, name: 'bool' = False, formatter: 'Callable | None' = None, na_rep: 'str_t' = 'NaN') -> 'list[str_t]'\n",
      " |      Render a string representation of the Index.\n",
      " |\n",
      " |  get_indexer(self, target, method: 'ReindexMethod | None' = None, limit: 'int | None' = None, tolerance=None) -> 'npt.NDArray[np.intp]'\n",
      " |      Compute indexer and mask for new index given the current index.\n",
      " |\n",
      " |      The indexer should be then used as an input to ndarray.take to align the\n",
      " |      current data to the new index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      target : Index\n",
      " |      method : {None, 'pad'/'ffill', 'backfill'/'bfill', 'nearest'}, optional\n",
      " |          * default: exact matches only.\n",
      " |          * pad / ffill: find the PREVIOUS index value if no exact match.\n",
      " |          * backfill / bfill: use NEXT index value if no exact match\n",
      " |          * nearest: use the NEAREST index value if no exact match. Tied\n",
      " |            distances are broken by preferring the larger index value.\n",
      " |      limit : int, optional\n",
      " |          Maximum number of consecutive labels in ``target`` to match for\n",
      " |          inexact matches.\n",
      " |      tolerance : optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations must\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |\n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      np.ndarray[np.intp]\n",
      " |          Integers from 0 to n - 1 indicating that the index at these\n",
      " |          positions matches the corresponding target values. Missing values\n",
      " |          in the target are marked by -1.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Returns -1 for unmatched values, for further explanation see the\n",
      " |      example below.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = pd.Index(['c', 'a', 'b'])\n",
      " |      >>> index.get_indexer(['a', 'b', 'x'])\n",
      " |      array([ 1,  2, -1])\n",
      " |\n",
      " |      Notice that the return value is an array of locations in ``index``\n",
      " |      and ``x`` is marked by -1, as it is not in ``index``.\n",
      " |\n",
      " |  get_indexer_for(self, target) -> 'npt.NDArray[np.intp]'\n",
      " |      Guaranteed return of an indexer even when non-unique.\n",
      " |\n",
      " |      This dispatches to get_indexer or get_indexer_non_unique\n",
      " |      as appropriate.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      np.ndarray[np.intp]\n",
      " |          List of indices.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([np.nan, 'var1', np.nan])\n",
      " |      >>> idx.get_indexer_for([np.nan])\n",
      " |      array([0, 2])\n",
      " |\n",
      " |  get_indexer_non_unique(self, target) -> 'tuple[npt.NDArray[np.intp], npt.NDArray[np.intp]]'\n",
      " |      Compute indexer and mask for new index given the current index.\n",
      " |\n",
      " |      The indexer should be then used as an input to ndarray.take to align the\n",
      " |      current data to the new index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      target : Index\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      indexer : np.ndarray[np.intp]\n",
      " |          Integers from 0 to n - 1 indicating that the index at these\n",
      " |          positions matches the corresponding target values. Missing values\n",
      " |          in the target are marked by -1.\n",
      " |      missing : np.ndarray[np.intp]\n",
      " |          An indexer into the target of the values not found.\n",
      " |          These correspond to the -1 in the indexer array.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = pd.Index(['c', 'b', 'a', 'b', 'b'])\n",
      " |      >>> index.get_indexer_non_unique(['b', 'b'])\n",
      " |      (array([1, 3, 4, 1, 3, 4]), array([], dtype=int64))\n",
      " |\n",
      " |      In the example below there are no matched values.\n",
      " |\n",
      " |      >>> index = pd.Index(['c', 'b', 'a', 'b', 'b'])\n",
      " |      >>> index.get_indexer_non_unique(['q', 'r', 't'])\n",
      " |      (array([-1, -1, -1]), array([0, 1, 2]))\n",
      " |\n",
      " |      For this reason, the returned ``indexer`` contains only integers equal to -1.\n",
      " |      It demonstrates that there's no match between the index and the ``target``\n",
      " |      values at these positions. The mask [0, 1, 2] in the return value shows that\n",
      " |      the first, second, and third elements are missing.\n",
      " |\n",
      " |      Notice that the return value is a tuple contains two items. In the example\n",
      " |      below the first item is an array of locations in ``index``. The second\n",
      " |      item is a mask shows that the first and third elements are missing.\n",
      " |\n",
      " |      >>> index = pd.Index(['c', 'b', 'a', 'b', 'b'])\n",
      " |      >>> index.get_indexer_non_unique(['f', 'b', 's'])\n",
      " |      (array([-1,  1,  3,  4, -1]), array([0, 2]))\n",
      " |\n",
      " |  get_level_values = _get_level_values(self, level) -> 'Index'\n",
      " |\n",
      " |  get_slice_bound(self, label, side: \"Literal['left', 'right']\") -> 'int'\n",
      " |      Calculate slice bound that corresponds to given label.\n",
      " |\n",
      " |      Returns leftmost (one-past-the-rightmost if ``side=='right'``) position\n",
      " |      of given label.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      label : object\n",
      " |      side : {'left', 'right'}\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |          Index of label.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.get_loc : Get integer location, slice or boolean mask for requested\n",
      " |          label.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.RangeIndex(5)\n",
      " |      >>> idx.get_slice_bound(3, 'left')\n",
      " |      3\n",
      " |\n",
      " |      >>> idx.get_slice_bound(3, 'right')\n",
      " |      4\n",
      " |\n",
      " |      If ``label`` is non-unique in the index, an error will be raised.\n",
      " |\n",
      " |      >>> idx_duplicate = pd.Index(['a', 'b', 'a', 'c', 'd'])\n",
      " |      >>> idx_duplicate.get_slice_bound('a', 'left')\n",
      " |      Traceback (most recent call last):\n",
      " |      KeyError: Cannot get left slice bound for non-unique label: 'a'\n",
      " |\n",
      " |  groupby(self, values) -> 'PrettyDict[Hashable, np.ndarray]'\n",
      " |      Group the index labels by a given array of values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : array\n",
      " |          Values used to determine the groups.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict\n",
      " |          {group name -> group labels}\n",
      " |\n",
      " |  holds_integer(self) -> 'bool'\n",
      " |      Whether the type is an integer type.\n",
      " |\n",
      " |      .. deprecated:: 2.0.0\n",
      " |          Use `pandas.api.types.infer_dtype` instead\n",
      " |\n",
      " |  identical(self, other) -> 'bool'\n",
      " |      Similar to equals, but checks that object attributes and types are also equal.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          If two Index objects have equal elements and same type True,\n",
      " |          otherwise False.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx1 = pd.Index(['1', '2', '3'])\n",
      " |      >>> idx2 = pd.Index(['1', '2', '3'])\n",
      " |      >>> idx2.identical(idx1)\n",
      " |      True\n",
      " |\n",
      " |      >>> idx1 = pd.Index(['1', '2', '3'], name=\"A\")\n",
      " |      >>> idx2 = pd.Index(['1', '2', '3'], name=\"B\")\n",
      " |      >>> idx2.identical(idx1)\n",
      " |      False\n",
      " |\n",
      " |  infer_objects(self, copy: 'bool' = True) -> 'Index'\n",
      " |      If we have an object dtype, try to infer a non-object dtype.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      copy : bool, default True\n",
      " |          Whether to make a copy in cases where no inference occurs.\n",
      " |\n",
      " |  intersection(self, other, sort: 'bool' = False)\n",
      " |      Form the intersection of two Index objects.\n",
      " |\n",
      " |      This returns a new Index with elements common to the index and `other`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Index or array-like\n",
      " |      sort : True, False or None, default False\n",
      " |          Whether to sort the resulting index.\n",
      " |\n",
      " |          * None : sort the result, except when `self` and `other` are equal\n",
      " |            or when the values cannot be compared.\n",
      " |          * False : do not sort the result.\n",
      " |          * True : Sort the result (which may raise TypeError).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx1 = pd.Index([1, 2, 3, 4])\n",
      " |      >>> idx2 = pd.Index([3, 4, 5, 6])\n",
      " |      >>> idx1.intersection(idx2)\n",
      " |      Index([3, 4], dtype='int64')\n",
      " |\n",
      " |  is_(self, other) -> 'bool'\n",
      " |      More flexible, faster check like ``is`` but that works through views.\n",
      " |\n",
      " |      Note: this is *not* the same as ``Index.identical()``, which checks\n",
      " |      that metadata is also the same.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : object\n",
      " |          Other object to compare against.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if both have same underlying data, False otherwise.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.identical : Works like ``Index.is_`` but also checks metadata.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx1 = pd.Index(['1', '2', '3'])\n",
      " |      >>> idx1.is_(idx1.view())\n",
      " |      True\n",
      " |\n",
      " |      >>> idx1.is_(idx1.copy())\n",
      " |      False\n",
      " |\n",
      " |  is_boolean(self) -> 'bool'\n",
      " |      Check if the Index only consists of booleans.\n",
      " |\n",
      " |      .. deprecated:: 2.0.0\n",
      " |          Use `pandas.api.types.is_bool_dtype` instead.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          Whether or not the Index only consists of booleans.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      is_integer : Check if the Index only consists of integers (deprecated).\n",
      " |      is_floating : Check if the Index is a floating type (deprecated).\n",
      " |      is_numeric : Check if the Index only consists of numeric data (deprecated).\n",
      " |      is_object : Check if the Index is of the object dtype (deprecated).\n",
      " |      is_categorical : Check if the Index holds categorical data.\n",
      " |      is_interval : Check if the Index holds Interval objects (deprecated).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([True, False, True])\n",
      " |      >>> idx.is_boolean()  # doctest: +SKIP\n",
      " |      True\n",
      " |\n",
      " |      >>> idx = pd.Index([\"True\", \"False\", \"True\"])\n",
      " |      >>> idx.is_boolean()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |      >>> idx = pd.Index([True, False, \"True\"])\n",
      " |      >>> idx.is_boolean()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |  is_categorical(self) -> 'bool'\n",
      " |      Check if the Index holds categorical data.\n",
      " |\n",
      " |      .. deprecated:: 2.0.0\n",
      " |            Use `isinstance(index.dtype, pd.CategoricalDtype)` instead.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if the Index is categorical.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      CategoricalIndex : Index for categorical data.\n",
      " |      is_boolean : Check if the Index only consists of booleans (deprecated).\n",
      " |      is_integer : Check if the Index only consists of integers (deprecated).\n",
      " |      is_floating : Check if the Index is a floating type (deprecated).\n",
      " |      is_numeric : Check if the Index only consists of numeric data (deprecated).\n",
      " |      is_object : Check if the Index is of the object dtype. (deprecated).\n",
      " |      is_interval : Check if the Index holds Interval objects (deprecated).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([\"Watermelon\", \"Orange\", \"Apple\",\n",
      " |      ...                 \"Watermelon\"]).astype(\"category\")\n",
      " |      >>> idx.is_categorical()  # doctest: +SKIP\n",
      " |      True\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 3, 5, 7])\n",
      " |      >>> idx.is_categorical()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |      >>> s = pd.Series([\"Peter\", \"Victor\", \"Elisabeth\", \"Mar\"])\n",
      " |      >>> s\n",
      " |      0        Peter\n",
      " |      1       Victor\n",
      " |      2    Elisabeth\n",
      " |      3          Mar\n",
      " |      dtype: object\n",
      " |      >>> s.index.is_categorical()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |  is_floating(self) -> 'bool'\n",
      " |      Check if the Index is a floating type.\n",
      " |\n",
      " |      .. deprecated:: 2.0.0\n",
      " |          Use `pandas.api.types.is_float_dtype` instead\n",
      " |\n",
      " |      The Index may consist of only floats, NaNs, or a mix of floats,\n",
      " |      integers, or NaNs.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          Whether or not the Index only consists of only consists of floats, NaNs, or\n",
      " |          a mix of floats, integers, or NaNs.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      is_boolean : Check if the Index only consists of booleans (deprecated).\n",
      " |      is_integer : Check if the Index only consists of integers (deprecated).\n",
      " |      is_numeric : Check if the Index only consists of numeric data (deprecated).\n",
      " |      is_object : Check if the Index is of the object dtype. (deprecated).\n",
      " |      is_categorical : Check if the Index holds categorical data (deprecated).\n",
      " |      is_interval : Check if the Index holds Interval objects (deprecated).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([1.0, 2.0, 3.0, 4.0])\n",
      " |      >>> idx.is_floating()  # doctest: +SKIP\n",
      " |      True\n",
      " |\n",
      " |      >>> idx = pd.Index([1.0, 2.0, np.nan, 4.0])\n",
      " |      >>> idx.is_floating()  # doctest: +SKIP\n",
      " |      True\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3, 4, np.nan])\n",
      " |      >>> idx.is_floating()  # doctest: +SKIP\n",
      " |      True\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3, 4])\n",
      " |      >>> idx.is_floating()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |  is_integer(self) -> 'bool'\n",
      " |      Check if the Index only consists of integers.\n",
      " |\n",
      " |      .. deprecated:: 2.0.0\n",
      " |          Use `pandas.api.types.is_integer_dtype` instead.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          Whether or not the Index only consists of integers.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      is_boolean : Check if the Index only consists of booleans (deprecated).\n",
      " |      is_floating : Check if the Index is a floating type (deprecated).\n",
      " |      is_numeric : Check if the Index only consists of numeric data (deprecated).\n",
      " |      is_object : Check if the Index is of the object dtype. (deprecated).\n",
      " |      is_categorical : Check if the Index holds categorical data (deprecated).\n",
      " |      is_interval : Check if the Index holds Interval objects (deprecated).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([1, 2, 3, 4])\n",
      " |      >>> idx.is_integer()  # doctest: +SKIP\n",
      " |      True\n",
      " |\n",
      " |      >>> idx = pd.Index([1.0, 2.0, 3.0, 4.0])\n",
      " |      >>> idx.is_integer()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |      >>> idx = pd.Index([\"Apple\", \"Mango\", \"Watermelon\"])\n",
      " |      >>> idx.is_integer()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |  is_interval(self) -> 'bool'\n",
      " |      Check if the Index holds Interval objects.\n",
      " |\n",
      " |      .. deprecated:: 2.0.0\n",
      " |          Use `isinstance(index.dtype, pd.IntervalDtype)` instead.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          Whether or not the Index holds Interval objects.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      IntervalIndex : Index for Interval objects.\n",
      " |      is_boolean : Check if the Index only consists of booleans (deprecated).\n",
      " |      is_integer : Check if the Index only consists of integers (deprecated).\n",
      " |      is_floating : Check if the Index is a floating type (deprecated).\n",
      " |      is_numeric : Check if the Index only consists of numeric data (deprecated).\n",
      " |      is_object : Check if the Index is of the object dtype. (deprecated).\n",
      " |      is_categorical : Check if the Index holds categorical data (deprecated).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([pd.Interval(left=0, right=5),\n",
      " |      ...                 pd.Interval(left=5, right=10)])\n",
      " |      >>> idx.is_interval()  # doctest: +SKIP\n",
      " |      True\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 3, 5, 7])\n",
      " |      >>> idx.is_interval()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |  is_numeric(self) -> 'bool'\n",
      " |      Check if the Index only consists of numeric data.\n",
      " |\n",
      " |      .. deprecated:: 2.0.0\n",
      " |          Use `pandas.api.types.is_numeric_dtype` instead.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          Whether or not the Index only consists of numeric data.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      is_boolean : Check if the Index only consists of booleans (deprecated).\n",
      " |      is_integer : Check if the Index only consists of integers (deprecated).\n",
      " |      is_floating : Check if the Index is a floating type (deprecated).\n",
      " |      is_object : Check if the Index is of the object dtype. (deprecated).\n",
      " |      is_categorical : Check if the Index holds categorical data (deprecated).\n",
      " |      is_interval : Check if the Index holds Interval objects (deprecated).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([1.0, 2.0, 3.0, 4.0])\n",
      " |      >>> idx.is_numeric()  # doctest: +SKIP\n",
      " |      True\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3, 4.0])\n",
      " |      >>> idx.is_numeric()  # doctest: +SKIP\n",
      " |      True\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3, 4])\n",
      " |      >>> idx.is_numeric()  # doctest: +SKIP\n",
      " |      True\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3, 4.0, np.nan])\n",
      " |      >>> idx.is_numeric()  # doctest: +SKIP\n",
      " |      True\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3, 4.0, np.nan, \"Apple\"])\n",
      " |      >>> idx.is_numeric()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |  is_object(self) -> 'bool'\n",
      " |      Check if the Index is of the object dtype.\n",
      " |\n",
      " |      .. deprecated:: 2.0.0\n",
      " |         Use `pandas.api.types.is_object_dtype` instead.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          Whether or not the Index is of the object dtype.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      is_boolean : Check if the Index only consists of booleans (deprecated).\n",
      " |      is_integer : Check if the Index only consists of integers (deprecated).\n",
      " |      is_floating : Check if the Index is a floating type (deprecated).\n",
      " |      is_numeric : Check if the Index only consists of numeric data (deprecated).\n",
      " |      is_categorical : Check if the Index holds categorical data (deprecated).\n",
      " |      is_interval : Check if the Index holds Interval objects (deprecated).\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([\"Apple\", \"Mango\", \"Watermelon\"])\n",
      " |      >>> idx.is_object()  # doctest: +SKIP\n",
      " |      True\n",
      " |\n",
      " |      >>> idx = pd.Index([\"Apple\", \"Mango\", 2.0])\n",
      " |      >>> idx.is_object()  # doctest: +SKIP\n",
      " |      True\n",
      " |\n",
      " |      >>> idx = pd.Index([\"Watermelon\", \"Orange\", \"Apple\",\n",
      " |      ...                 \"Watermelon\"]).astype(\"category\")\n",
      " |      >>> idx.is_object()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |      >>> idx = pd.Index([1.0, 2.0, 3.0, 4.0])\n",
      " |      >>> idx.is_object()  # doctest: +SKIP\n",
      " |      False\n",
      " |\n",
      " |  isin(self, values, level=None) -> 'npt.NDArray[np.bool_]'\n",
      " |      Return a boolean array where the index values are in `values`.\n",
      " |\n",
      " |      Compute boolean array of whether each index value is found in the\n",
      " |      passed set of values. The length of the returned boolean array matches\n",
      " |      the length of the index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : set or list-like\n",
      " |          Sought values.\n",
      " |      level : str or int, optional\n",
      " |          Name or position of the index level to use (if the index is a\n",
      " |          `MultiIndex`).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      np.ndarray[bool]\n",
      " |          NumPy array of boolean values.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.isin : Same for Series.\n",
      " |      DataFrame.isin : Same method for DataFrames.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      In the case of `MultiIndex` you must either specify `values` as a\n",
      " |      list-like object containing tuples that are the same length as the\n",
      " |      number of levels, or specify `level`. Otherwise it will raise a\n",
      " |      ``ValueError``.\n",
      " |\n",
      " |      If `level` is specified:\n",
      " |\n",
      " |      - if it is the name of one *and only one* index level, use that level;\n",
      " |      - otherwise it should be a number indicating level position.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([1,2,3])\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |\n",
      " |      Check whether each index value in a list of values.\n",
      " |\n",
      " |      >>> idx.isin([1, 4])\n",
      " |      array([ True, False, False])\n",
      " |\n",
      " |      >>> midx = pd.MultiIndex.from_arrays([[1,2,3],\n",
      " |      ...                                  ['red', 'blue', 'green']],\n",
      " |      ...                                  names=('number', 'color'))\n",
      " |      >>> midx\n",
      " |      MultiIndex([(1,   'red'),\n",
      " |                  (2,  'blue'),\n",
      " |                  (3, 'green')],\n",
      " |                 names=['number', 'color'])\n",
      " |\n",
      " |      Check whether the strings in the 'color' level of the MultiIndex\n",
      " |      are in a list of colors.\n",
      " |\n",
      " |      >>> midx.isin(['red', 'orange', 'yellow'], level='color')\n",
      " |      array([ True, False, False])\n",
      " |\n",
      " |      To check across the levels of a MultiIndex, pass a list of tuples:\n",
      " |\n",
      " |      >>> midx.isin([(1, 'red'), (3, 'red')])\n",
      " |      array([ True, False, False])\n",
      " |\n",
      " |  isna(self) -> 'npt.NDArray[np.bool_]'\n",
      " |      Detect missing values.\n",
      " |\n",
      " |      Return a boolean same-sized object indicating if the values are NA.\n",
      " |      NA values, such as ``None``, :attr:`numpy.NaN` or :attr:`pd.NaT`, get\n",
      " |      mapped to ``True`` values.\n",
      " |      Everything else get mapped to ``False`` values. Characters such as\n",
      " |      empty strings `''` or :attr:`numpy.inf` are not considered NA values.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray[bool]\n",
      " |          A boolean array of whether my values are NA.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.notna : Boolean inverse of isna.\n",
      " |      Index.dropna : Omit entries with missing values.\n",
      " |      isna : Top-level isna.\n",
      " |      Series.isna : Detect missing values in Series object.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in a pandas.Index are NA. The result is an\n",
      " |      array.\n",
      " |\n",
      " |      >>> idx = pd.Index([5.2, 6.0, np.nan])\n",
      " |      >>> idx\n",
      " |      Index([5.2, 6.0, nan], dtype='float64')\n",
      " |      >>> idx.isna()\n",
      " |      array([False, False,  True])\n",
      " |\n",
      " |      Empty strings are not considered NA values. None is considered an NA\n",
      " |      value.\n",
      " |\n",
      " |      >>> idx = pd.Index(['black', '', 'red', None])\n",
      " |      >>> idx\n",
      " |      Index(['black', '', 'red', None], dtype='object')\n",
      " |      >>> idx.isna()\n",
      " |      array([False, False, False,  True])\n",
      " |\n",
      " |      For datetimes, `NaT` (Not a Time) is considered as an NA value.\n",
      " |\n",
      " |      >>> idx = pd.DatetimeIndex([pd.Timestamp('1940-04-25'),\n",
      " |      ...                         pd.Timestamp(''), None, pd.NaT])\n",
      " |      >>> idx\n",
      " |      DatetimeIndex(['1940-04-25', 'NaT', 'NaT', 'NaT'],\n",
      " |                    dtype='datetime64[ns]', freq=None)\n",
      " |      >>> idx.isna()\n",
      " |      array([False,  True,  True,  True])\n",
      " |\n",
      " |  isnull = isna(self) -> 'npt.NDArray[np.bool_]'\n",
      " |\n",
      " |  join(self, other: 'Index', *, how: 'JoinHow' = 'left', level: 'Level | None' = None, return_indexers: 'bool' = False, sort: 'bool' = False) -> 'Index | tuple[Index, npt.NDArray[np.intp] | None, npt.NDArray[np.intp] | None]'\n",
      " |      Compute join_index and indexers to conform data structures to the new index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Index\n",
      " |      how : {'left', 'right', 'inner', 'outer'}\n",
      " |      level : int or level name, default None\n",
      " |      return_indexers : bool, default False\n",
      " |      sort : bool, default False\n",
      " |          Sort the join keys lexicographically in the result Index. If False,\n",
      " |          the order of the join keys depends on the join type (how keyword).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      join_index, (left_indexer, right_indexer)\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx1 = pd.Index([1, 2, 3])\n",
      " |      >>> idx2 = pd.Index([4, 5, 6])\n",
      " |      >>> idx1.join(idx2, how='outer')\n",
      " |      Index([1, 2, 3, 4, 5, 6], dtype='int64')\n",
      " |\n",
      " |  map(self, mapper, na_action: \"Literal['ignore'] | None\" = None)\n",
      " |      Map values using an input mapping or function.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : function, dict, or Series\n",
      " |          Mapping correspondence.\n",
      " |      na_action : {None, 'ignore'}\n",
      " |          If 'ignore', propagate NA values, without passing them to the\n",
      " |          mapping correspondence.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Union[Index, MultiIndex]\n",
      " |          The output of the mapping function applied to the index.\n",
      " |          If the function returns a tuple with more than one element\n",
      " |          a MultiIndex will be returned.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx.map({1: 'a', 2: 'b', 3: 'c'})\n",
      " |      Index(['a', 'b', 'c'], dtype='object')\n",
      " |\n",
      " |      Using `map` with a function:\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx.map('I am a {}'.format)\n",
      " |      Index(['I am a 1', 'I am a 2', 'I am a 3'], dtype='object')\n",
      " |\n",
      " |      >>> idx = pd.Index(['a', 'b', 'c'])\n",
      " |      >>> idx.map(lambda x: x.upper())\n",
      " |      Index(['A', 'B', 'C'], dtype='object')\n",
      " |\n",
      " |  notna(self) -> 'npt.NDArray[np.bool_]'\n",
      " |      Detect existing (non-missing) values.\n",
      " |\n",
      " |      Return a boolean same-sized object indicating if the values are not NA.\n",
      " |      Non-missing values get mapped to ``True``. Characters such as empty\n",
      " |      strings ``''`` or :attr:`numpy.inf` are not considered NA values.\n",
      " |      NA values, such as None or :attr:`numpy.NaN`, get mapped to ``False``\n",
      " |      values.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray[bool]\n",
      " |          Boolean array to indicate which entries are not NA.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.notnull : Alias of notna.\n",
      " |      Index.isna: Inverse of notna.\n",
      " |      notna : Top-level notna.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Show which entries in an Index are not NA. The result is an\n",
      " |      array.\n",
      " |\n",
      " |      >>> idx = pd.Index([5.2, 6.0, np.nan])\n",
      " |      >>> idx\n",
      " |      Index([5.2, 6.0, nan], dtype='float64')\n",
      " |      >>> idx.notna()\n",
      " |      array([ True,  True, False])\n",
      " |\n",
      " |      Empty strings are not considered NA values. None is considered a NA\n",
      " |      value.\n",
      " |\n",
      " |      >>> idx = pd.Index(['black', '', 'red', None])\n",
      " |      >>> idx\n",
      " |      Index(['black', '', 'red', None], dtype='object')\n",
      " |      >>> idx.notna()\n",
      " |      array([ True,  True,  True, False])\n",
      " |\n",
      " |  notnull = notna(self) -> 'npt.NDArray[np.bool_]'\n",
      " |\n",
      " |  putmask(self, mask, value) -> 'Index'\n",
      " |      Return a new Index of the values set with the mask.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.putmask : Changes elements of an array\n",
      " |          based on conditional and input values.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx1 = pd.Index([1, 2, 3])\n",
      " |      >>> idx2 = pd.Index([5, 6, 7])\n",
      " |      >>> idx1.putmask([True, False, False], idx2)\n",
      " |      Index([5, 2, 3], dtype='int64')\n",
      " |\n",
      " |  ravel(self, order: 'str_t' = 'C') -> 'Self'\n",
      " |      Return a view on self.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.ravel : Return a flattened array.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
      " |      >>> s.index.ravel()\n",
      " |      Index(['a', 'b', 'c'], dtype='object')\n",
      " |\n",
      " |  reindex(self, target, method: 'ReindexMethod | None' = None, level=None, limit: 'int | None' = None, tolerance: 'float | None' = None) -> 'tuple[Index, npt.NDArray[np.intp] | None]'\n",
      " |      Create index with target's values.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      target : an iterable\n",
      " |      method : {None, 'pad'/'ffill', 'backfill'/'bfill', 'nearest'}, optional\n",
      " |          * default: exact matches only.\n",
      " |          * pad / ffill: find the PREVIOUS index value if no exact match.\n",
      " |          * backfill / bfill: use NEXT index value if no exact match\n",
      " |          * nearest: use the NEAREST index value if no exact match. Tied\n",
      " |            distances are broken by preferring the larger index value.\n",
      " |      level : int, optional\n",
      " |          Level of multiindex.\n",
      " |      limit : int, optional\n",
      " |          Maximum number of consecutive labels in ``target`` to match for\n",
      " |          inexact matches.\n",
      " |      tolerance : int or float, optional\n",
      " |          Maximum distance between original and new labels for inexact\n",
      " |          matches. The values of the index at the matching locations must\n",
      " |          satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n",
      " |\n",
      " |          Tolerance may be a scalar value, which applies the same tolerance\n",
      " |          to all values, or list-like, which applies variable tolerance per\n",
      " |          element. List-like includes list, tuple, array, Series, and must be\n",
      " |          the same size as the index and its dtype must exactly match the\n",
      " |          index's type.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      new_index : pd.Index\n",
      " |          Resulting index.\n",
      " |      indexer : np.ndarray[np.intp] or None\n",
      " |          Indices of output values in original index.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      TypeError\n",
      " |          If ``method`` passed along with ``level``.\n",
      " |      ValueError\n",
      " |          If non-unique multi-index\n",
      " |      ValueError\n",
      " |          If non-unique index and ``method`` or ``limit`` passed.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.reindex : Conform Series to new index with optional filling logic.\n",
      " |      DataFrame.reindex : Conform DataFrame to new index with optional filling logic.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index(['car', 'bike', 'train', 'tractor'])\n",
      " |      >>> idx\n",
      " |      Index(['car', 'bike', 'train', 'tractor'], dtype='object')\n",
      " |      >>> idx.reindex(['car', 'bike'])\n",
      " |      (Index(['car', 'bike'], dtype='object'), array([0, 1]))\n",
      " |\n",
      " |  rename(self, name, *, inplace: 'bool' = False) -> 'Self | None'\n",
      " |      Alter Index or MultiIndex name.\n",
      " |\n",
      " |      Able to set new names without level. Defaults to returning new index.\n",
      " |      Length of names must match number of levels in MultiIndex.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : label or list of labels\n",
      " |          Name(s) to set.\n",
      " |      inplace : bool, default False\n",
      " |          Modifies the object directly, instead of creating a new Index or\n",
      " |          MultiIndex.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index or None\n",
      " |          The same type as the caller or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.set_names : Able to set new names partially and by level.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index(['A', 'C', 'A', 'B'], name='score')\n",
      " |      >>> idx.rename('grade')\n",
      " |      Index(['A', 'C', 'A', 'B'], dtype='object', name='grade')\n",
      " |\n",
      " |      >>> idx = pd.MultiIndex.from_product([['python', 'cobra'],\n",
      " |      ...                                   [2018, 2019]],\n",
      " |      ...                                   names=['kind', 'year'])\n",
      " |      >>> idx\n",
      " |      MultiIndex([('python', 2018),\n",
      " |                  ('python', 2019),\n",
      " |                  ( 'cobra', 2018),\n",
      " |                  ( 'cobra', 2019)],\n",
      " |                 names=['kind', 'year'])\n",
      " |      >>> idx.rename(['species', 'year'])\n",
      " |      MultiIndex([('python', 2018),\n",
      " |                  ('python', 2019),\n",
      " |                  ( 'cobra', 2018),\n",
      " |                  ( 'cobra', 2019)],\n",
      " |                 names=['species', 'year'])\n",
      " |      >>> idx.rename('species')\n",
      " |      Traceback (most recent call last):\n",
      " |      TypeError: Must pass list-like as `names`.\n",
      " |\n",
      " |  repeat(self, repeats, axis: 'None' = None) -> 'Self'\n",
      " |      Repeat elements of a Index.\n",
      " |\n",
      " |      Returns a new Index where each element of the current Index\n",
      " |      is repeated consecutively a given number of times.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      repeats : int or array of ints\n",
      " |          The number of repetitions for each element. This should be a\n",
      " |          non-negative integer. Repeating 0 times will return an empty\n",
      " |          Index.\n",
      " |      axis : None\n",
      " |          Must be ``None``. Has no effect but is accepted for compatibility\n",
      " |          with numpy.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          Newly created Index with repeated elements.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.repeat : Equivalent function for Series.\n",
      " |      numpy.repeat : Similar method for :class:`numpy.ndarray`.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index(['a', 'b', 'c'])\n",
      " |      >>> idx\n",
      " |      Index(['a', 'b', 'c'], dtype='object')\n",
      " |      >>> idx.repeat(2)\n",
      " |      Index(['a', 'a', 'b', 'b', 'c', 'c'], dtype='object')\n",
      " |      >>> idx.repeat([1, 2, 3])\n",
      " |      Index(['a', 'b', 'b', 'c', 'c', 'c'], dtype='object')\n",
      " |\n",
      " |  round(self, decimals: 'int' = 0) -> 'Self'\n",
      " |      Round each value in the Index to the given number of decimals.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      decimals : int, optional\n",
      " |          Number of decimal places to round to. If decimals is negative,\n",
      " |          it specifies the number of positions to the left of the decimal point.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |          A new Index with the rounded values.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> idx = pd.Index([10.1234, 20.5678, 30.9123, 40.4567, 50.7890])\n",
      " |      >>> idx.round(decimals=2)\n",
      " |      Index([10.12, 20.57, 30.91, 40.46, 50.79], dtype='float64')\n",
      " |\n",
      " |  set_names(self, names, *, level=None, inplace: 'bool' = False) -> 'Self | None'\n",
      " |      Set Index or MultiIndex name.\n",
      " |\n",
      " |      Able to set new names partially and by level.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |\n",
      " |      names : label or list of label or dict-like for MultiIndex\n",
      " |          Name(s) to set.\n",
      " |\n",
      " |          .. versionchanged:: 1.3.0\n",
      " |\n",
      " |      level : int, label or list of int or label, optional\n",
      " |          If the index is a MultiIndex and names is not dict-like, level(s) to set\n",
      " |          (None for all levels). Otherwise level must be None.\n",
      " |\n",
      " |          .. versionchanged:: 1.3.0\n",
      " |\n",
      " |      inplace : bool, default False\n",
      " |          Modifies the object directly, instead of creating a new Index or\n",
      " |          MultiIndex.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index or None\n",
      " |          The same type as the caller or None if ``inplace=True``.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.rename : Able to set new names without level.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([1, 2, 3, 4])\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3, 4], dtype='int64')\n",
      " |      >>> idx.set_names('quarter')\n",
      " |      Index([1, 2, 3, 4], dtype='int64', name='quarter')\n",
      " |\n",
      " |      >>> idx = pd.MultiIndex.from_product([['python', 'cobra'],\n",
      " |      ...                                   [2018, 2019]])\n",
      " |      >>> idx\n",
      " |      MultiIndex([('python', 2018),\n",
      " |                  ('python', 2019),\n",
      " |                  ( 'cobra', 2018),\n",
      " |                  ( 'cobra', 2019)],\n",
      " |                 )\n",
      " |      >>> idx = idx.set_names(['kind', 'year'])\n",
      " |      >>> idx.set_names('species', level=0)\n",
      " |      MultiIndex([('python', 2018),\n",
      " |                  ('python', 2019),\n",
      " |                  ( 'cobra', 2018),\n",
      " |                  ( 'cobra', 2019)],\n",
      " |                 names=['species', 'year'])\n",
      " |\n",
      " |      When renaming levels with a dict, levels can not be passed.\n",
      " |\n",
      " |      >>> idx.set_names({'kind': 'snake'})\n",
      " |      MultiIndex([('python', 2018),\n",
      " |                  ('python', 2019),\n",
      " |                  ( 'cobra', 2018),\n",
      " |                  ( 'cobra', 2019)],\n",
      " |                 names=['snake', 'year'])\n",
      " |\n",
      " |  shift(self, periods: 'int' = 1, freq=None)\n",
      " |      Shift index by desired number of time frequency increments.\n",
      " |\n",
      " |      This method is for shifting the values of datetime-like indexes\n",
      " |      by a specified time increment a given number of times.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Number of periods (or increments) to shift by,\n",
      " |          can be positive or negative.\n",
      " |      freq : pandas.DateOffset, pandas.Timedelta or str, optional\n",
      " |          Frequency increment to shift by.\n",
      " |          If None, the index is shifted by its own `freq` attribute.\n",
      " |          Offset aliases are valid strings, e.g., 'D', 'W', 'M' etc.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Index\n",
      " |          Shifted index.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.shift : Shift values of Series.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is only implemented for datetime-like index classes,\n",
      " |      i.e., DatetimeIndex, PeriodIndex and TimedeltaIndex.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Put the first 5 month starts of 2011 into an index.\n",
      " |\n",
      " |      >>> month_starts = pd.date_range('1/1/2011', periods=5, freq='MS')\n",
      " |      >>> month_starts\n",
      " |      DatetimeIndex(['2011-01-01', '2011-02-01', '2011-03-01', '2011-04-01',\n",
      " |                     '2011-05-01'],\n",
      " |                    dtype='datetime64[ns]', freq='MS')\n",
      " |\n",
      " |      Shift the index by 10 days.\n",
      " |\n",
      " |      >>> month_starts.shift(10, freq='D')\n",
      " |      DatetimeIndex(['2011-01-11', '2011-02-11', '2011-03-11', '2011-04-11',\n",
      " |                     '2011-05-11'],\n",
      " |                    dtype='datetime64[ns]', freq=None)\n",
      " |\n",
      " |      The default value of `freq` is the `freq` attribute of the index,\n",
      " |      which is 'MS' (month start) in this example.\n",
      " |\n",
      " |      >>> month_starts.shift(10)\n",
      " |      DatetimeIndex(['2011-11-01', '2011-12-01', '2012-01-01', '2012-02-01',\n",
      " |                     '2012-03-01'],\n",
      " |                    dtype='datetime64[ns]', freq='MS')\n",
      " |\n",
      " |  slice_indexer(self, start: 'Hashable | None' = None, end: 'Hashable | None' = None, step: 'int | None' = None) -> 'slice'\n",
      " |      Compute the slice indexer for input labels and step.\n",
      " |\n",
      " |      Index needs to be ordered and unique.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start : label, default None\n",
      " |          If None, defaults to the beginning.\n",
      " |      end : label, default None\n",
      " |          If None, defaults to the end.\n",
      " |      step : int, default None\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      slice\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      KeyError : If key does not exist, or key is not unique and index is\n",
      " |          not ordered.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This function assumes that the data is sorted, so use at your own peril\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      This is a method on all index types. For example you can do:\n",
      " |\n",
      " |      >>> idx = pd.Index(list('abcd'))\n",
      " |      >>> idx.slice_indexer(start='b', end='c')\n",
      " |      slice(1, 3, None)\n",
      " |\n",
      " |      >>> idx = pd.MultiIndex.from_arrays([list('abcd'), list('efgh')])\n",
      " |      >>> idx.slice_indexer(start='b', end=('c', 'g'))\n",
      " |      slice(1, 3, None)\n",
      " |\n",
      " |  slice_locs(self, start=None, end=None, step=None) -> 'tuple[int, int]'\n",
      " |      Compute slice locations for input labels.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start : label, default None\n",
      " |          If None, defaults to the beginning.\n",
      " |      end : label, default None\n",
      " |          If None, defaults to the end.\n",
      " |      step : int, defaults None\n",
      " |          If None, defaults to 1.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      tuple[int, int]\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.get_loc : Get location for a single label.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method only works if the index is monotonic or unique.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index(list('abcd'))\n",
      " |      >>> idx.slice_locs(start='b', end='c')\n",
      " |      (1, 3)\n",
      " |\n",
      " |  sort(self, *args, **kwargs)\n",
      " |      Use sort_values instead.\n",
      " |\n",
      " |  sortlevel(self, level=None, ascending: 'bool | list[bool]' = True, sort_remaining=None, na_position: 'NaPosition' = 'first')\n",
      " |      For internal compatibility with the Index API.\n",
      " |\n",
      " |      Sort the Index. This is for compat with MultiIndex\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ascending : bool, default True\n",
      " |          False to sort in descending order\n",
      " |      na_position : {'first' or 'last'}, default 'first'\n",
      " |          Argument 'first' puts NaNs at the beginning, 'last' puts NaNs at\n",
      " |          the end.\n",
      " |\n",
      " |          .. versionadded:: 2.1.0\n",
      " |\n",
      " |      level, sort_remaining are compat parameters\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |\n",
      " |  to_flat_index(self) -> 'Self'\n",
      " |      Identity method.\n",
      " |\n",
      " |      This is implemented for compatibility with subclass implementations\n",
      " |      when chaining.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pd.Index\n",
      " |          Caller.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      MultiIndex.to_flat_index : Subclass implementation.\n",
      " |\n",
      " |  to_frame(self, index: 'bool' = True, name: 'Hashable' = <no_default>) -> 'DataFrame'\n",
      " |      Create a DataFrame with a column containing the Index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool, default True\n",
      " |          Set the index of the returned DataFrame as the original Index.\n",
      " |\n",
      " |      name : object, defaults to index.name\n",
      " |          The passed name should substitute for the index name (if it has\n",
      " |          one).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          DataFrame containing the original Index data.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.to_series : Convert an Index to a Series.\n",
      " |      Series.to_frame : Convert Series to DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index(['Ant', 'Bear', 'Cow'], name='animal')\n",
      " |      >>> idx.to_frame()\n",
      " |             animal\n",
      " |      animal\n",
      " |      Ant       Ant\n",
      " |      Bear     Bear\n",
      " |      Cow       Cow\n",
      " |\n",
      " |      By default, the original Index is reused. To enforce a new Index:\n",
      " |\n",
      " |      >>> idx.to_frame(index=False)\n",
      " |          animal\n",
      " |      0   Ant\n",
      " |      1  Bear\n",
      " |      2   Cow\n",
      " |\n",
      " |      To override the name of the resulting column, specify `name`:\n",
      " |\n",
      " |      >>> idx.to_frame(index=False, name='zoo')\n",
      " |          zoo\n",
      " |      0   Ant\n",
      " |      1  Bear\n",
      " |      2   Cow\n",
      " |\n",
      " |  to_series(self, index=None, name: 'Hashable | None' = None) -> 'Series'\n",
      " |      Create a Series with both index and values equal to the index keys.\n",
      " |\n",
      " |      Useful with map for returning an indexer based on an index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : Index, optional\n",
      " |          Index of resulting Series. If None, defaults to original index.\n",
      " |      name : str, optional\n",
      " |          Name of resulting Series. If None, defaults to name of original\n",
      " |          index.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |          The dtype will be based on the type of the Index values.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.to_frame : Convert an Index to a DataFrame.\n",
      " |      Series.to_frame : Convert Series to DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index(['Ant', 'Bear', 'Cow'], name='animal')\n",
      " |\n",
      " |      By default, the original index and original name is reused.\n",
      " |\n",
      " |      >>> idx.to_series()\n",
      " |      animal\n",
      " |      Ant      Ant\n",
      " |      Bear    Bear\n",
      " |      Cow      Cow\n",
      " |      Name: animal, dtype: object\n",
      " |\n",
      " |      To enforce a new index, specify new labels to ``index``:\n",
      " |\n",
      " |      >>> idx.to_series(index=[0, 1, 2])\n",
      " |      0     Ant\n",
      " |      1    Bear\n",
      " |      2     Cow\n",
      " |      Name: animal, dtype: object\n",
      " |\n",
      " |      To override the name of the resulting column, specify ``name``:\n",
      " |\n",
      " |      >>> idx.to_series(name='zoo')\n",
      " |      animal\n",
      " |      Ant      Ant\n",
      " |      Bear    Bear\n",
      " |      Cow      Cow\n",
      " |      Name: zoo, dtype: object\n",
      " |\n",
      " |  union(self, other, sort=None)\n",
      " |      Form the union of two Index objects.\n",
      " |\n",
      " |      If the Index objects are incompatible, both Index objects will be\n",
      " |      cast to dtype('object') first.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Index or array-like\n",
      " |      sort : bool or None, default None\n",
      " |          Whether to sort the resulting Index.\n",
      " |\n",
      " |          * None : Sort the result, except when\n",
      " |\n",
      " |            1. `self` and `other` are equal.\n",
      " |            2. `self` or `other` has length 0.\n",
      " |            3. Some values in `self` or `other` cannot be compared.\n",
      " |               A RuntimeWarning is issued in this case.\n",
      " |\n",
      " |          * False : do not sort the result.\n",
      " |          * True : Sort the result (which may raise TypeError).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      Union matching dtypes\n",
      " |\n",
      " |      >>> idx1 = pd.Index([1, 2, 3, 4])\n",
      " |      >>> idx2 = pd.Index([3, 4, 5, 6])\n",
      " |      >>> idx1.union(idx2)\n",
      " |      Index([1, 2, 3, 4, 5, 6], dtype='int64')\n",
      " |\n",
      " |      Union mismatched dtypes\n",
      " |\n",
      " |      >>> idx1 = pd.Index(['a', 'b', 'c', 'd'])\n",
      " |      >>> idx2 = pd.Index([1, 2, 3, 4])\n",
      " |      >>> idx1.union(idx2)\n",
      " |      Index(['a', 'b', 'c', 'd', 1, 2, 3, 4], dtype='object')\n",
      " |\n",
      " |      MultiIndex case\n",
      " |\n",
      " |      >>> idx1 = pd.MultiIndex.from_arrays(\n",
      " |      ...     [[1, 1, 2, 2], [\"Red\", \"Blue\", \"Red\", \"Blue\"]]\n",
      " |      ... )\n",
      " |      >>> idx1\n",
      " |      MultiIndex([(1,  'Red'),\n",
      " |          (1, 'Blue'),\n",
      " |          (2,  'Red'),\n",
      " |          (2, 'Blue')],\n",
      " |         )\n",
      " |      >>> idx2 = pd.MultiIndex.from_arrays(\n",
      " |      ...     [[3, 3, 2, 2], [\"Red\", \"Green\", \"Red\", \"Green\"]]\n",
      " |      ... )\n",
      " |      >>> idx2\n",
      " |      MultiIndex([(3,   'Red'),\n",
      " |          (3, 'Green'),\n",
      " |          (2,   'Red'),\n",
      " |          (2, 'Green')],\n",
      " |         )\n",
      " |      >>> idx1.union(idx2)\n",
      " |      MultiIndex([(1,  'Blue'),\n",
      " |          (1,   'Red'),\n",
      " |          (2,  'Blue'),\n",
      " |          (2, 'Green'),\n",
      " |          (2,   'Red'),\n",
      " |          (3, 'Green'),\n",
      " |          (3,   'Red')],\n",
      " |         )\n",
      " |      >>> idx1.union(idx2, sort=False)\n",
      " |      MultiIndex([(1,   'Red'),\n",
      " |          (1,  'Blue'),\n",
      " |          (2,   'Red'),\n",
      " |          (2,  'Blue'),\n",
      " |          (3,   'Red'),\n",
      " |          (3, 'Green'),\n",
      " |          (2, 'Green')],\n",
      " |         )\n",
      " |\n",
      " |  unique(self, level: 'Hashable | None' = None) -> 'Self'\n",
      " |      Return unique values in the index.\n",
      " |\n",
      " |      Unique values are returned in order of appearance, this does NOT sort.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int or hashable, optional\n",
      " |          Only return values from specified level (for MultiIndex).\n",
      " |          If int, gets the level by integer position, else by level name.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Index\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      unique : Numpy array of unique values in that column.\n",
      " |      Series.unique : Return unique values of Series object.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([1, 1, 2, 3, 3])\n",
      " |      >>> idx.unique()\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |\n",
      " |  view(self, cls=None)\n",
      " |\n",
      " |  where(self, cond, other=None) -> 'Index'\n",
      " |      Replace values where the condition is False.\n",
      " |\n",
      " |      The replacement is taken from other.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : bool array-like with the same length as self\n",
      " |          Condition to select the values on.\n",
      " |      other : scalar, or array-like, default None\n",
      " |          Replacement if the condition is False.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      pandas.Index\n",
      " |          A copy of self with values replaced from other\n",
      " |          where the condition is False.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.where : Same method for Series.\n",
      " |      DataFrame.where : Same method for DataFrame.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index(['car', 'bike', 'train', 'tractor'])\n",
      " |      >>> idx\n",
      " |      Index(['car', 'bike', 'train', 'tractor'], dtype='object')\n",
      " |      >>> idx.where(idx.isin(['car', 'train']), 'other')\n",
      " |      Index(['car', 'other', 'train', 'other'], dtype='object')\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.indexes.base.Index:\n",
      " |\n",
      " |  has_duplicates\n",
      " |      Check if the Index has duplicate values.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          Whether or not the Index has duplicate values.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.is_unique : Inverse method that checks if it has unique values.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([1, 5, 7, 7])\n",
      " |      >>> idx.has_duplicates\n",
      " |      True\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 5, 7])\n",
      " |      >>> idx.has_duplicates\n",
      " |      False\n",
      " |\n",
      " |      >>> idx = pd.Index([\"Watermelon\", \"Orange\", \"Apple\",\n",
      " |      ...                 \"Watermelon\"]).astype(\"category\")\n",
      " |      >>> idx.has_duplicates\n",
      " |      True\n",
      " |\n",
      " |      >>> idx = pd.Index([\"Orange\", \"Apple\",\n",
      " |      ...                 \"Watermelon\"]).astype(\"category\")\n",
      " |      >>> idx.has_duplicates\n",
      " |      False\n",
      " |\n",
      " |  nlevels\n",
      " |      Number of levels.\n",
      " |\n",
      " |  shape\n",
      " |      Return a tuple of the shape of the underlying data.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |      >>> idx.shape\n",
      " |      (3,)\n",
      " |\n",
      " |  values\n",
      " |      Return an array representing the data in the Index.\n",
      " |\n",
      " |      .. warning::\n",
      " |\n",
      " |         We recommend using :attr:`Index.array` or\n",
      " |         :meth:`Index.to_numpy`, depending on whether you need\n",
      " |         a reference to the underlying data or a NumPy array.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      array: numpy.ndarray or ExtensionArray\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.array : Reference to the underlying data.\n",
      " |      Index.to_numpy : A NumPy array representing the underlying data.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For :class:`pandas.Index`:\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |      >>> idx.values\n",
      " |      array([1, 2, 3])\n",
      " |\n",
      " |      For :class:`pandas.IntervalIndex`:\n",
      " |\n",
      " |      >>> idx = pd.interval_range(start=0, end=5)\n",
      " |      >>> idx.values\n",
      " |      <IntervalArray>\n",
      " |      [(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]]\n",
      " |      Length: 5, dtype: interval[int64, right]\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.indexes.base.Index:\n",
      " |\n",
      " |  array\n",
      " |      The ExtensionArray of the data backing this Series or Index.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      ExtensionArray\n",
      " |          An ExtensionArray of the values stored within. For extension\n",
      " |          types, this is the actual array. For NumPy native types, this\n",
      " |          is a thin (no copy) wrapper around :class:`numpy.ndarray`.\n",
      " |\n",
      " |          ``.array`` differs from ``.values``, which may require converting\n",
      " |          the data to a different form.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Index.to_numpy : Similar method that always returns a NumPy array.\n",
      " |      Series.to_numpy : Similar method that always returns a NumPy array.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      This table lays out the different array types for each extension\n",
      " |      dtype within pandas.\n",
      " |\n",
      " |      ================== =============================\n",
      " |      dtype              array type\n",
      " |      ================== =============================\n",
      " |      category           Categorical\n",
      " |      period             PeriodArray\n",
      " |      interval           IntervalArray\n",
      " |      IntegerNA          IntegerArray\n",
      " |      string             StringArray\n",
      " |      boolean            BooleanArray\n",
      " |      datetime64[ns, tz] DatetimeArray\n",
      " |      ================== =============================\n",
      " |\n",
      " |      For any 3rd-party extension types, the array type will be an\n",
      " |      ExtensionArray.\n",
      " |\n",
      " |      For all remaining dtypes ``.array`` will be a\n",
      " |      :class:`arrays.NumpyExtensionArray` wrapping the actual ndarray\n",
      " |      stored within. If you absolutely need a NumPy array (possibly with\n",
      " |      copying / coercing data), then use :meth:`Series.to_numpy` instead.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For regular NumPy types like int, and float, a NumpyExtensionArray\n",
      " |      is returned.\n",
      " |\n",
      " |      >>> pd.Series([1, 2, 3]).array\n",
      " |      <NumpyExtensionArray>\n",
      " |      [1, 2, 3]\n",
      " |      Length: 3, dtype: int64\n",
      " |\n",
      " |      For extension types, like Categorical, the actual ExtensionArray\n",
      " |      is returned\n",
      " |\n",
      " |      >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\n",
      " |      >>> ser.array\n",
      " |      ['a', 'b', 'a']\n",
      " |      Categories (2, object): ['a', 'b']\n",
      " |\n",
      " |  hasnans\n",
      " |      Return True if there are any NaNs.\n",
      " |\n",
      " |      Enables various performance speedups.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 2, 3], index=['a', 'b', None])\n",
      " |      >>> s\n",
      " |      a    1\n",
      " |      b    2\n",
      " |      None 3\n",
      " |      dtype: int64\n",
      " |      >>> s.index.hasnans\n",
      " |      True\n",
      " |\n",
      " |  name\n",
      " |      Return Index or MultiIndex name.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> idx = pd.Index([1, 2, 3], name='x')\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3], dtype='int64',  name='x')\n",
      " |      >>> idx.name\n",
      " |      'x'\n",
      " |\n",
      " |  names\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.indexes.base.Index:\n",
      " |\n",
      " |  __pandas_priority__ = 2000\n",
      " |\n",
      " |  str = <class 'pandas.core.strings.accessor.StringMethods'>\n",
      " |      Vectorized string functions for Series and Index.\n",
      " |\n",
      " |      NAs stay NA unless handled otherwise by a particular method.\n",
      " |      Patterned after Python's string methods, with some inspiration from\n",
      " |      R's stringr package.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([\"A_Str_Series\"])\n",
      " |      >>> s\n",
      " |      0    A_Str_Series\n",
      " |      dtype: object\n",
      " |\n",
      " |      >>> s.str.split(\"_\")\n",
      " |      0    [A, Str, Series]\n",
      " |      dtype: object\n",
      " |\n",
      " |      >>> s.str.replace(\"_\", \"\")\n",
      " |      0    AStrSeries\n",
      " |      dtype: object\n",
      " |\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.IndexOpsMixin:\n",
      " |\n",
      " |  item(self)\n",
      " |      Return the first element of the underlying data as a Python scalar.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      scalar\n",
      " |          The first element of Series or Index.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the data is not length = 1.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1])\n",
      " |      >>> s.item()\n",
      " |      1\n",
      " |\n",
      " |      For an index:\n",
      " |\n",
      " |      >>> s = pd.Series([1], index=['a'])\n",
      " |      >>> s.index.item()\n",
      " |      'a'\n",
      " |\n",
      " |  nunique(self, dropna: 'bool' = True) -> 'int'\n",
      " |      Return number of unique elements in the object.\n",
      " |\n",
      " |      Excludes NA values by default.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dropna : bool, default True\n",
      " |          Don't include NaN in the count.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      int\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.nunique: Method nunique for DataFrame.\n",
      " |      Series.count: Count non-NA/null observations in the Series.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series([1, 3, 5, 7, 7])\n",
      " |      >>> s\n",
      " |      0    1\n",
      " |      1    3\n",
      " |      2    5\n",
      " |      3    7\n",
      " |      4    7\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> s.nunique()\n",
      " |      4\n",
      " |\n",
      " |  searchsorted(self, value: 'NumpyValueArrayLike | ExtensionArray', side: \"Literal['left', 'right']\" = 'left', sorter: 'NumpySorter | None' = None) -> 'npt.NDArray[np.intp] | np.intp'\n",
      " |      Find indices where elements should be inserted to maintain order.\n",
      " |\n",
      " |      Find the indices into a sorted Index `self` such that, if the\n",
      " |      corresponding elements in `value` were inserted before the indices,\n",
      " |      the order of `self` would be preserved.\n",
      " |\n",
      " |      .. note::\n",
      " |\n",
      " |          The Index *must* be monotonically sorted, otherwise\n",
      " |          wrong locations will likely be returned. Pandas does *not*\n",
      " |          check this for you.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      value : array-like or scalar\n",
      " |          Values to insert into `self`.\n",
      " |      side : {'left', 'right'}, optional\n",
      " |          If 'left', the index of the first suitable location found is given.\n",
      " |          If 'right', return the last such index.  If there is no suitable\n",
      " |          index, return either 0 or N (where N is the length of `self`).\n",
      " |      sorter : 1-D array-like, optional\n",
      " |          Optional array of integer indices that sort `self` into ascending\n",
      " |          order. They are typically the result of ``np.argsort``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      int or array of int\n",
      " |          A scalar or array of insertion points with the\n",
      " |          same shape as `value`.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      sort_values : Sort by the values along either axis.\n",
      " |      numpy.searchsorted : Similar method from NumPy.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Binary search is used to find the required insertion points.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series([1, 2, 3])\n",
      " |      >>> ser\n",
      " |      0    1\n",
      " |      1    2\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> ser.searchsorted(4)\n",
      " |      3\n",
      " |\n",
      " |      >>> ser.searchsorted([0, 4])\n",
      " |      array([0, 3])\n",
      " |\n",
      " |      >>> ser.searchsorted([1, 3], side='left')\n",
      " |      array([0, 2])\n",
      " |\n",
      " |      >>> ser.searchsorted([1, 3], side='right')\n",
      " |      array([1, 3])\n",
      " |\n",
      " |      >>> ser = pd.Series(pd.to_datetime(['3/11/2000', '3/12/2000', '3/13/2000']))\n",
      " |      >>> ser\n",
      " |      0   2000-03-11\n",
      " |      1   2000-03-12\n",
      " |      2   2000-03-13\n",
      " |      dtype: datetime64[ns]\n",
      " |\n",
      " |      >>> ser.searchsorted('3/14/2000')\n",
      " |      3\n",
      " |\n",
      " |      >>> ser = pd.Categorical(\n",
      " |      ...     ['apple', 'bread', 'bread', 'cheese', 'milk'], ordered=True\n",
      " |      ... )\n",
      " |      >>> ser\n",
      " |      ['apple', 'bread', 'bread', 'cheese', 'milk']\n",
      " |      Categories (4, object): ['apple' < 'bread' < 'cheese' < 'milk']\n",
      " |\n",
      " |      >>> ser.searchsorted('bread')\n",
      " |      1\n",
      " |\n",
      " |      >>> ser.searchsorted(['bread'], side='right')\n",
      " |      array([3])\n",
      " |\n",
      " |      If the values are not monotonically sorted, wrong locations\n",
      " |      may be returned:\n",
      " |\n",
      " |      >>> ser = pd.Series([2, 1, 3])\n",
      " |      >>> ser\n",
      " |      0    2\n",
      " |      1    1\n",
      " |      2    3\n",
      " |      dtype: int64\n",
      " |\n",
      " |      >>> ser.searchsorted(1)  # doctest: +SKIP\n",
      " |      0  # wrong result, correct would be 1\n",
      " |\n",
      " |  to_list = tolist(self)\n",
      " |      Return a list of the values.\n",
      " |\n",
      " |      These are each a scalar type, which is a Python scalar\n",
      " |      (for str, int, float) or a pandas scalar\n",
      " |      (for Timestamp/Timedelta/Interval/Period)\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      list\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.tolist : Return the array as an a.ndim-levels deep\n",
      " |          nested list of Python scalars.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series\n",
      " |\n",
      " |      >>> s = pd.Series([1, 2, 3])\n",
      " |      >>> s.to_list()\n",
      " |      [1, 2, 3]\n",
      " |\n",
      " |      For Index:\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |\n",
      " |      >>> idx.to_list()\n",
      " |      [1, 2, 3]\n",
      " |\n",
      " |  to_numpy(self, dtype: 'npt.DTypeLike | None' = None, copy: 'bool' = False, na_value: 'object' = <no_default>, **kwargs) -> 'np.ndarray'\n",
      " |      A NumPy ndarray representing the values in this Series or Index.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : str or numpy.dtype, optional\n",
      " |          The dtype to pass to :meth:`numpy.asarray`.\n",
      " |      copy : bool, default False\n",
      " |          Whether to ensure that the returned value is not a view on\n",
      " |          another array. Note that ``copy=False`` does not *ensure* that\n",
      " |          ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\n",
      " |          a copy is made, even if not strictly necessary.\n",
      " |      na_value : Any, optional\n",
      " |          The value to use for missing values. The default value depends\n",
      " |          on `dtype` and the type of the array.\n",
      " |      **kwargs\n",
      " |          Additional keywords passed through to the ``to_numpy`` method\n",
      " |          of the underlying array (for extension arrays).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.array : Get the actual data stored within.\n",
      " |      Index.array : Get the actual data stored within.\n",
      " |      DataFrame.to_numpy : Similar method for DataFrame.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The returned array will be the same up to equality (values equal\n",
      " |      in `self` will be equal in the returned array; likewise for values\n",
      " |      that are not equal). When `self` contains an ExtensionArray, the\n",
      " |      dtype may be different. For example, for a category-dtype Series,\n",
      " |      ``to_numpy()`` will return a NumPy array and the categorical dtype\n",
      " |      will be lost.\n",
      " |\n",
      " |      For NumPy dtypes, this will be a reference to the actual data stored\n",
      " |      in this Series or Index (assuming ``copy=False``). Modifying the result\n",
      " |      in place will modify the data stored in the Series or Index (not that\n",
      " |      we recommend doing that).\n",
      " |\n",
      " |      For extension types, ``to_numpy()`` *may* require copying data and\n",
      " |      coercing the result to a NumPy type (possibly object), which may be\n",
      " |      expensive. When you need a no-copy reference to the underlying data,\n",
      " |      :attr:`Series.array` should be used instead.\n",
      " |\n",
      " |      This table lays out the different dtypes and default return types of\n",
      " |      ``to_numpy()`` for various dtypes within pandas.\n",
      " |\n",
      " |      ================== ================================\n",
      " |      dtype              array type\n",
      " |      ================== ================================\n",
      " |      category[T]        ndarray[T] (same dtype as input)\n",
      " |      period             ndarray[object] (Periods)\n",
      " |      interval           ndarray[object] (Intervals)\n",
      " |      IntegerNA          ndarray[object]\n",
      " |      datetime64[ns]     datetime64[ns]\n",
      " |      datetime64[ns, tz] ndarray[object] (Timestamps)\n",
      " |      ================== ================================\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> ser = pd.Series(pd.Categorical(['a', 'b', 'a']))\n",
      " |      >>> ser.to_numpy()\n",
      " |      array(['a', 'b', 'a'], dtype=object)\n",
      " |\n",
      " |      Specify the `dtype` to control how datetime-aware data is represented.\n",
      " |      Use ``dtype=object`` to return an ndarray of pandas :class:`Timestamp`\n",
      " |      objects, each with the correct ``tz``.\n",
      " |\n",
      " |      >>> ser = pd.Series(pd.date_range('2000', periods=2, tz=\"CET\"))\n",
      " |      >>> ser.to_numpy(dtype=object)\n",
      " |      array([Timestamp('2000-01-01 00:00:00+0100', tz='CET'),\n",
      " |             Timestamp('2000-01-02 00:00:00+0100', tz='CET')],\n",
      " |            dtype=object)\n",
      " |\n",
      " |      Or ``dtype='datetime64[ns]'`` to return an ndarray of native\n",
      " |      datetime64 values. The values are converted to UTC and the timezone\n",
      " |      info is dropped.\n",
      " |\n",
      " |      >>> ser.to_numpy(dtype=\"datetime64[ns]\")\n",
      " |      ... # doctest: +ELLIPSIS\n",
      " |      array(['1999-12-31T23:00:00.000000000', '2000-01-01T23:00:00...'],\n",
      " |            dtype='datetime64[ns]')\n",
      " |\n",
      " |  transpose(self, *args, **kwargs) -> 'Self'\n",
      " |      Return the transpose, which is by definition self.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      %(klass)s\n",
      " |\n",
      " |  value_counts(self, normalize: 'bool' = False, sort: 'bool' = True, ascending: 'bool' = False, bins=None, dropna: 'bool' = True) -> 'Series'\n",
      " |      Return a Series containing counts of unique values.\n",
      " |\n",
      " |      The resulting object will be in descending order so that the\n",
      " |      first element is the most frequently-occurring element.\n",
      " |      Excludes NA values by default.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      normalize : bool, default False\n",
      " |          If True then the object returned will contain the relative\n",
      " |          frequencies of the unique values.\n",
      " |      sort : bool, default True\n",
      " |          Sort by frequencies when True. Preserve the order of the data when False.\n",
      " |      ascending : bool, default False\n",
      " |          Sort in ascending order.\n",
      " |      bins : int, optional\n",
      " |          Rather than count values, group them into half-open bins,\n",
      " |          a convenience for ``pd.cut``, only works with numeric data.\n",
      " |      dropna : bool, default True\n",
      " |          Don't include counts of NaN.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.count: Number of non-NA elements in a Series.\n",
      " |      DataFrame.count: Number of non-NA elements in a DataFrame.\n",
      " |      DataFrame.value_counts: Equivalent method on DataFrames.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = pd.Index([3, 1, 2, 3, 4, np.nan])\n",
      " |      >>> index.value_counts()\n",
      " |      3.0    2\n",
      " |      1.0    1\n",
      " |      2.0    1\n",
      " |      4.0    1\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |      With `normalize` set to `True`, returns the relative frequency by\n",
      " |      dividing all values by the sum of values.\n",
      " |\n",
      " |      >>> s = pd.Series([3, 1, 2, 3, 4, np.nan])\n",
      " |      >>> s.value_counts(normalize=True)\n",
      " |      3.0    0.4\n",
      " |      1.0    0.2\n",
      " |      2.0    0.2\n",
      " |      4.0    0.2\n",
      " |      Name: proportion, dtype: float64\n",
      " |\n",
      " |      **bins**\n",
      " |\n",
      " |      Bins can be useful for going from a continuous variable to a\n",
      " |      categorical variable; instead of counting unique\n",
      " |      apparitions of values, divide the index in the specified\n",
      " |      number of half-open bins.\n",
      " |\n",
      " |      >>> s.value_counts(bins=3)\n",
      " |      (0.996, 2.0]    2\n",
      " |      (2.0, 3.0]      2\n",
      " |      (3.0, 4.0]      1\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |      **dropna**\n",
      " |\n",
      " |      With `dropna` set to `False` we can also see NaN index values.\n",
      " |\n",
      " |      >>> s.value_counts(dropna=False)\n",
      " |      3.0    2\n",
      " |      1.0    1\n",
      " |      2.0    1\n",
      " |      4.0    1\n",
      " |      NaN    1\n",
      " |      Name: count, dtype: int64\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pandas.core.base.IndexOpsMixin:\n",
      " |\n",
      " |  T\n",
      " |      Return the transpose, which is by definition self.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      For Series:\n",
      " |\n",
      " |      >>> s = pd.Series(['Ant', 'Bear', 'Cow'])\n",
      " |      >>> s\n",
      " |      0     Ant\n",
      " |      1    Bear\n",
      " |      2     Cow\n",
      " |      dtype: object\n",
      " |      >>> s.T\n",
      " |      0     Ant\n",
      " |      1    Bear\n",
      " |      2     Cow\n",
      " |      dtype: object\n",
      " |\n",
      " |      For Index:\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx.T\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |\n",
      " |  empty\n",
      " |\n",
      " |  ndim\n",
      " |      Number of dimensions of the underlying data, by definition 1.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = pd.Series(['Ant', 'Bear', 'Cow'])\n",
      " |      >>> s\n",
      " |      0     Ant\n",
      " |      1    Bear\n",
      " |      2     Cow\n",
      " |      dtype: object\n",
      " |      >>> s.ndim\n",
      " |      1\n",
      " |\n",
      " |      For Index:\n",
      " |\n",
      " |      >>> idx = pd.Index([1, 2, 3])\n",
      " |      >>> idx\n",
      " |      Index([1, 2, 3], dtype='int64')\n",
      " |      >>> idx.ndim\n",
      " |      1\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.base.IndexOpsMixin:\n",
      " |\n",
      " |  __array_priority__ = 1000\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.arraylike.OpsMixin:\n",
      " |\n",
      " |  __add__(self, other)\n",
      " |      Get Addition of DataFrame and other, column-wise.\n",
      " |\n",
      " |      Equivalent to ``DataFrame.add(other)``.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : scalar, sequence, Series, dict or DataFrame\n",
      " |          Object to be added to the DataFrame.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |          The result of adding ``other`` to DataFrame.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      DataFrame.add : Add a DataFrame and another object, with option for index-\n",
      " |          or column-oriented addition.\n",
      " |\n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'height': [1.5, 2.6], 'weight': [500, 800]},\n",
      " |      ...                   index=['elk', 'moose'])\n",
      " |      >>> df\n",
      " |             height  weight\n",
      " |      elk       1.5     500\n",
      " |      moose     2.6     800\n",
      " |\n",
      " |      Adding a scalar affects all rows and columns.\n",
      " |\n",
      " |      >>> df[['height', 'weight']] + 1.5\n",
      " |             height  weight\n",
      " |      elk       3.0   501.5\n",
      " |      moose     4.1   801.5\n",
      " |\n",
      " |      Each element of a list is added to a column of the DataFrame, in order.\n",
      " |\n",
      " |      >>> df[['height', 'weight']] + [0.5, 1.5]\n",
      " |             height  weight\n",
      " |      elk       2.0   501.5\n",
      " |      moose     3.1   801.5\n",
      " |\n",
      " |      Keys of a dictionary are aligned to the DataFrame, based on column names;\n",
      " |      each value in the dictionary is added to the corresponding column.\n",
      " |\n",
      " |      >>> df[['height', 'weight']] + {'height': 0.5, 'weight': 1.5}\n",
      " |             height  weight\n",
      " |      elk       2.0   501.5\n",
      " |      moose     3.1   801.5\n",
      " |\n",
      " |      When `other` is a :class:`Series`, the index of `other` is aligned with the\n",
      " |      columns of the DataFrame.\n",
      " |\n",
      " |      >>> s1 = pd.Series([0.5, 1.5], index=['weight', 'height'])\n",
      " |      >>> df[['height', 'weight']] + s1\n",
      " |             height  weight\n",
      " |      elk       3.0   500.5\n",
      " |      moose     4.1   800.5\n",
      " |\n",
      " |      Even when the index of `other` is the same as the index of the DataFrame,\n",
      " |      the :class:`Series` will not be reoriented. If index-wise alignment is desired,\n",
      " |      :meth:`DataFrame.add` should be used with `axis='index'`.\n",
      " |\n",
      " |      >>> s2 = pd.Series([0.5, 1.5], index=['elk', 'moose'])\n",
      " |      >>> df[['height', 'weight']] + s2\n",
      " |             elk  height  moose  weight\n",
      " |      elk    NaN     NaN    NaN     NaN\n",
      " |      moose  NaN     NaN    NaN     NaN\n",
      " |\n",
      " |      >>> df[['height', 'weight']].add(s2, axis='index')\n",
      " |             height  weight\n",
      " |      elk       2.0   500.5\n",
      " |      moose     4.1   801.5\n",
      " |\n",
      " |      When `other` is a :class:`DataFrame`, both columns names and the\n",
      " |      index are aligned.\n",
      " |\n",
      " |      >>> other = pd.DataFrame({'height': [0.2, 0.4, 0.6]},\n",
      " |      ...                      index=['elk', 'moose', 'deer'])\n",
      " |      >>> df[['height', 'weight']] + other\n",
      " |             height  weight\n",
      " |      deer      NaN     NaN\n",
      " |      elk       1.7     NaN\n",
      " |      moose     3.0     NaN\n",
      " |\n",
      " |  __and__(self, other)\n",
      " |\n",
      " |  __divmod__(self, other)\n",
      " |\n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |\n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |\n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |\n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |\n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |\n",
      " |  __mod__(self, other)\n",
      " |\n",
      " |  __mul__(self, other)\n",
      " |\n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |\n",
      " |  __or__(self, other)\n",
      " |      Return self|value.\n",
      " |\n",
      " |  __pow__(self, other)\n",
      " |\n",
      " |  __radd__(self, other)\n",
      " |\n",
      " |  __rand__(self, other)\n",
      " |\n",
      " |  __rdivmod__(self, other)\n",
      " |\n",
      " |  __rfloordiv__(self, other)\n",
      " |\n",
      " |  __rmod__(self, other)\n",
      " |\n",
      " |  __rmul__(self, other)\n",
      " |\n",
      " |  __ror__(self, other)\n",
      " |      Return value|self.\n",
      " |\n",
      " |  __rpow__(self, other)\n",
      " |\n",
      " |  __rsub__(self, other)\n",
      " |\n",
      " |  __rtruediv__(self, other)\n",
      " |\n",
      " |  __rxor__(self, other)\n",
      " |\n",
      " |  __sub__(self, other)\n",
      " |\n",
      " |  __truediv__(self, other)\n",
      " |\n",
      " |  __xor__(self, other)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.arraylike.OpsMixin:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.arraylike.OpsMixin:\n",
      " |\n",
      " |  __hash__ = None\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |\n",
      " |  __sizeof__(self) -> 'int'\n",
      " |      Generates the total memory usage for an object that returns\n",
      " |      either a value or Series of values\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.accessor.DirNamesMixin:\n",
      " |\n",
      " |  __dir__(self) -> 'list[str]'\n",
      " |      Provide method name lookup and completion.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Only provide 'public' methods.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(s.index) #클래스에는 항상 속성과 메서드가 존재한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89305e55-36b7-42c0-820c-f410652f2cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "메로나    1000\n",
       "월드콘    2000\n",
       "와      3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시리즈 생성하면서 인덱스도 같이 생성\n",
    "data = [1000,2000,3000]\n",
    "index=[\"메로나\",\"월드콘\",\"와\"]\n",
    "s = pd.Series(data,index)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "909cb5ed-a0ca-4408-9fc3-980e587d5441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1000, 2000, 3000]), numpy.ndarray)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.values,type(s.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9ec8b4-7ed8-4072-86a4-d8a9694b053a",
   "metadata": {},
   "source": [
    "## 시리즈 인덱싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66ff6d3f-14ab-483f-9be5-e1b4192b1df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(s.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f8efe28-f850-43c0-ab3a-6e916584f14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(s.loc['메로나'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1806c826-aeb7-4566-9a60-d30a33738c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'메로나'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m s2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(s2\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43ms2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m메로나\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[1;32m~\\Desktop\\alphco\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\alphco\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1431\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\alphco\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1381\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[0;32m   1380\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\alphco\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:4301\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4299\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[0;32m   4300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4301\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m   4304\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[1;32m~\\Desktop\\alphco\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '메로나'"
     ]
    }
   ],
   "source": [
    "data = [1000,2000,3000]\n",
    "#인덱스가 없음\n",
    "s2 = pd.Series(data=data)\n",
    "print(s2.iloc[0])\n",
    "print(s2.loc['메로나']) # loc는 값으로 처리를 하는거고 iloc는 인덱스 번호로 리리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a62835e-4303-49a7-95e8-d673e4f6dd46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(s2.iloc[0]) # 0은 위치 0을 의미\n",
    "print(s2.loc[0])# 0은 라벨 0을 의미 -데이터 프레임할때는 loc로만 기억하면 됨\n",
    "#둘은 같은 0이지만 전혀 다른값이라고 봐야한다\n",
    "\n",
    "#필터링 할때는 loc할때 쓰면 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1363718e-94f1-4015-9d1b-9729c2c2eb64",
   "metadata": {},
   "source": [
    "# 슬라이싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f70eb91-2e08-4309-8f5f-ba3f9fab0e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "메로나    1000\n",
       "월드콘    2000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.iloc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f28886ae-861d-4ff4-a2e0-93829da745d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "메로나    1000\n",
       "월드콘    2000\n",
       "와      3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.loc[\"메로나\":\"와\"] # loc는 직관적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc8aac3e-c435-4c98-821e-c9ce7014e52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1000\n",
       "1    2000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.iloc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d1a4256-7678-46c1-89f3-0e956f12a351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1000\n",
       "1    2000\n",
       "2    3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2.loc[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922c133f-3969-4155-9e0d-22588edd0fa0",
   "metadata": {},
   "source": [
    "## 시리즈 수정/추가/삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "78bc0902-0f36-4c56-9973-4aaa388c4493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "메로나    1000\n",
       "월드콘    2000\n",
       "와      3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [1000,2000,3000]\n",
    "index=[\"메로나\",\"월드콘\",\"와\"]\n",
    "s = pd.Series(data,index)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "03cb42f8-85ba-4614-8266-83d37924bad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "메로나     500\n",
       "월드콘    2000\n",
       "와      3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s['메로나']=500\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "520fa557-93a2-412a-bff7-edef86206405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "메로나     500\n",
       "월드콘    2000\n",
       "와      3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.iloc[0]=500\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f3967f8-0b49-4ddf-a916-f5e4074e7e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "메로나     500\n",
       "월드콘    2000\n",
       "와      3000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.loc['메로나'] = 500 #세가지 중에 이녀석을 추천\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df42eb33-ab3b-4c69-a319-9c3491b3293e",
   "metadata": {},
   "source": [
    "## 시리즈 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4dd5fc2-df4e-4d7b-bc9f-04f35cdc71f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLE    40\n",
       "NAVER    40\n",
       "엔비디아     40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evan = pd.Series([10,20,30], index=['NAVER','APPLE','엔비디아'])\n",
    "딸1= pd.Series([10,30,20],index= [\"엔비디아\",\"NAVER\",\"APPLE\"])\n",
    "\n",
    "#우리 가족이 보유하고 이는 주식의 숫자를 계산\n",
    "evan + 딸1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "30a9522f-654d-409c-b3ad-57d8059ed45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "엔비디아     10\n",
       "NAVER    30\n",
       "APPLE    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "딸1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af91c150-4cf5-485f-95d9-279a59413d78",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAVER    10\n",
       "APPLE    20\n",
       "엔비디아     30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3c35b9eb-88f7-4fd0-831e-e2fb6c17615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/1    650\n",
      "6/2    550\n",
      "6/3    750\n",
      "6/4    800\n",
      "6/5    650\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "date = [\"6/1\", \"6/2\", \"6/3\", \"6/4\", \"6/5\"]\n",
    "high = pd.Series([42800, 42700, 42050, 42950, 43000], index=date) #매도\n",
    "low = pd.Series([42150, 42150, 41300, 42150, 42350] , index=date)#수수\n",
    "\n",
    "diff =high - low\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3fbd9045-3e4b-4a3a-b993-af1cadb0c72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('6/4', np.int64(800))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 반복문을 바로 잡을수 있는 메서드\n",
    "diff.idxmax(),diff[diff.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3a7f5824-7310-44ee-9d31-abd96508bbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('6/2', np.int64(550))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.idxmin(),diff[diff.idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "011c06fb-0daf-4259-a302-adaa4d847cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6/1    1.015421\n",
       "6/2    1.013049\n",
       "6/3    1.018160\n",
       "6/4    1.018980\n",
       "6/5    1.015348\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit = high/low #단순 수익률 계산\n",
    "profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "04a2eb73-ea52-4bd0-8bb8-2300d905c19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6/1    1.015421\n",
       "6/2    1.028671\n",
       "6/3    1.047351\n",
       "6/4    1.067230\n",
       "6/5    1.083610\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit.cumprod() # 누적시키는값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f29a1a-83ec-49b9-ab26-b8626e0f9c34",
   "metadata": {},
   "source": [
    "# 시리즈와 map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "482877da-3990-4c33-883c-c5fac286da1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(int, 1234)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '1,234'\n",
    "result = int(text.replace(',',''))\n",
    "type(result),result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "150a8429-a5cc-47dd-80a6-5e0f093b43a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1234, 5678, 12345]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_str = ['1,234', '5,678', '12,345']\n",
    "results = []\n",
    "for num in num_str:\n",
    "    temp = int(num.replace(',',''))\n",
    "    results.append(temp)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7c1d30d0-7863-4dbf-8d6a-3b156b45ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_comma(x):\n",
    "    return int(x.replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "92018a61-afca-44b8-81d2-028a7b979ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1234\n",
       "1     5678\n",
       "2    12345\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s= pd.Series(['1,234', '5,678', '12,345'])\n",
    "result = s.map(rm_comma)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "32f41a9b-544a-420b-b43f-5e54a0f7306c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1234.56\n",
       "1     5678.90\n",
       "2    12345.67\n",
       "dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_dollar_sign(x):\n",
    "    return float(x.replace('$', '').replace(',', ''))\n",
    "s = pd.Series(['$1,234.56', '$5,678.90', '$12,345.67'])\n",
    "result = s.map(remove_dollar_sign)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c330ea-2f8a-4b6a-bd5b-1dfccc73ddc3",
   "metadata": {},
   "source": [
    "# 문제\n",
    "- 기준 13이상\n",
    "  + 크다 or 작다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "49b7432c-05a2-44e5-b173-cb5176925806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    작다\n",
       "1    크다\n",
       "2    작다\n",
       "3    크다\n",
       "4    크다\n",
       "dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_greater_13(x): \n",
    "\n",
    "    return_text = None\n",
    "    if x >= 13:\n",
    "        return \"크다\"\n",
    "    else:\n",
    "        return \"작다\" \n",
    "\n",
    "s = pd.Series([10, 15, 7, 20, 13])\n",
    "s.map(is_greater_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9db4bd38-da35-48d0-ab53-dae1d647d751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    작다\n",
       "1    크다\n",
       "2    작다\n",
       "3    크다\n",
       "4    크다\n",
       "dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = s.map(lambda x: '크다' if x >=13 else '작다')  # map이나 apply 동일하게 사용가능\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "092d4d5c-3bd1-46bc-8058-cc94d4e51422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "3     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([5, 10, 15, 20])\n",
    "s = s>=13\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a8471-76f5-4258-aead-a00693becdc6",
   "metadata": {},
   "source": [
    "## 필터링 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "53a2357a-ce42-4ce2-80a0-183865843593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-05-31    42500\n",
       "2019-05-30    42550\n",
       "2019-05-29    41800\n",
       "2019-05-28    42550\n",
       "2019-05-27    42650\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [42500, 42550, 41800, 42550, 42650]\n",
    "index = ['2019-05-31', '2019-05-30', '2019-05-29', '2019-05-28', '2019-05-27']\n",
    "s = pd.Series(data=data, index=index)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "49dc35df-48b7-4aa5-b2fc-7d201b7ea043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-31     True\n",
      "2019-05-30     True\n",
      "2019-05-29    False\n",
      "2019-05-28     True\n",
      "2019-05-27     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "cond = s > 42000\n",
    "print(cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5b1b1f0d-136f-4082-87ba-f173a0518436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-05-31    42500\n",
       "2019-05-30    42550\n",
       "2019-05-28    42550\n",
       "2019-05-27    42650\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6fc5c435-743f-4513-9bbd-8814f702d6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-05-31    42500\n",
       "2019-05-30    42550\n",
       "2019-05-28    42550\n",
       "2019-05-27    42650\n",
       "dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[s> 42000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2ff68caf-5c24-41e6-b8e5-d781fdeea761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-05-30    42550\n",
       "2019-05-27    42650\n",
       "dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close = [42500, 42550, 41800, 42550, 42650]\n",
    "open = [42600, 42200, 41850, 42550, 42500]\n",
    "index = ['2019-05-31', '2019-05-30', '2019-05-29', '2019-05-28', '2019-05-27']\n",
    "\n",
    "open = pd.Series(data=open, index=index) #싯가\n",
    "close = pd.Series(data=close, index=index) #종가\n",
    "\n",
    "# 종가가 싯가보다 높은 날을 구하세요\n",
    "\n",
    "close[close>open]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
